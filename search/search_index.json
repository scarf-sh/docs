{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to Scarf's documentation, your one-stop guide for understanding and leveraging our platform's powerful tools to track usage metrics for your open-source software projects.</p>"},{"location":"#about","title":"About","text":"<p>Scarf provides open-source software maintainers with deep insights about their project's usage. With best-in-class open-source usage analytics and tracking capabilities, Scarf uncovers how and where your software is being utilized, which companies are relying on it, and much more. This data helps maintainers understand their project's reach, identify growth opportunities, and make informed strategic decisions. With its ethos firmly rooted in the open-source community, Scarf is not just a platform but a partner in your software project's journey toward success.</p>"},{"location":"#documentation-sections-overview","title":"Documentation Sections Overview","text":"<ol> <li>Getting Started Checklist: Preview the high-level Scarf set up process.</li> <li>Quick Start: Jumpstart your journey with Scarf. A concise guide to get you up and running with our platform quickly.</li> <li>Scarf Gateway: Understand the nuances of Scarf's secure and powerful gateway.</li> <li>Organizations: Learn how to manage and collaborate with your teams within Scarf's platform.</li> <li>Monthly Tracked Companies (MTCs): Understand what MTCs are, how MTC quotas work, and how they apply to your organization.</li> <li>Packages: Delve into the specifics of working with various Scarf package types, such as Docker, Helm, npm, Python, and more.</li> <li>Scarf SDKs: Discover how our Software Development Kits (SDKs) can accelerate your development process.</li> <li>Custom Telemetry: Track any custom behaviors by sending event data to Scarf from your code. </li> <li>Documentation Insights (Pixels): Uncover insights about your product's usage and onboarding through Scarf's cookie-free pixel tracking.</li> <li>Open Source Qualified Leads (OQLs): Identify organizations and individuals that have engaged with your OSS.</li> <li>Open Source Adoption Funnel Stages: Understand the level of engagement of potential leads.</li> <li>Lead Generation : Learn how Scarf can help you connect with key contacts in companies using your OSS to drive revenue growth.</li> <li>Event Import: Bring event data from other applications and platforms into Scarf using the Event Import API.</li> <li>Data Export: Export your data for customized analysis. Explore the potential of data manipulation to suit your needs.</li> <li>CRM Integrations Overview: Understand the core concepts that apply to all CRM integrations.</li> <li>Salesforce: Set up and configure Scarf's native integration with Salesforce.</li> <li>Hubspot: Set up and configure Scarf's native integration with Hubspot.</li> <li>User Guide &amp; Best Practices: Make a plan to use the data uncovered in your OQLs.</li> <li>Troubleshooting: Find solutions to common issues and questions.</li> <li>API Docs: Understand the capabilities of a specific API version and its available endpoints.</li> </ol>"},{"location":"#contribution","title":"Contribution","text":"<p>Our documentation is an open-source resource hosted on GitHub. We welcome and appreciate your contributions to make it even better.</p> <p>For engaging discussions, interactive Q&amp;A sessions, and to meet our dynamic community of staff, open-source maintainers, and end-users, join the Scarf-Community workspace on Slack.</p> <p>Stay updated with Scarf's system status and uptime on our status page here.</p>"},{"location":"#welcome-aboard-and-happy-exploring","title":"Welcome aboard, and happy exploring!","text":""},{"location":"api-v2/","title":"API V2","text":""},{"location":"crm-overview/","title":"CRM Integrations Overview","text":""},{"location":"crm-overview/#introduction","title":"Introduction","text":"<p>Connecting Scarf to your CRM platform allows your internal Sales and Marketing teams to build business operations and Go-To-Market strategies leveraging the organization-level activity and adoption information collected using the Scarf Platform. Combining Scarf Insights with existing CRM Account profiles can help your team focus their efforts using the tools they\u2019re already familiar with.</p>"},{"location":"crm-overview/#matching-and-syncing-scarf-companies-to-crm-accounts","title":"Matching and Syncing Scarf Companies to CRM Accounts","text":"<p>Once a CRM Integration has been initialized, a <code>CRM Controls</code> button will be added to your Company Insights table, both on the Organization Dashboard and on the Insights page. Clicking on <code>CRM Controls</code> expands a \"CRM Connection\" column in the Insights table which displays the current CRM account paired to the Scarf Company (green dot) and allows you to search, edit and assign a match manually (empty check box). The <code>CRM Controls</code> button allows you to add multiple CRM connections as needed.</p> <p>The Company Insights table now also will display a \"Status\" column, allowing you to quickly observe which companies have been synced to the CRM, those which have been queued for the next sync run or any for which the sync has failed. Hovering over the status indicator will open a tool tip with more detail of the current status</p>"},{"location":"crm-overview/#matching-vs-syncing","title":"Matching vs. Syncing","text":"<p>Scarf\u2019s CRM integration allows for both reading and writing data, but these actions are distinct and configurable.</p>"},{"location":"crm-overview/#matching","title":"Matching","text":"<p>Matching refers to the process reading records from the CRM and associating a Scarf Company with an existing CRM Account.</p> <ul> <li>If Auto-Match is enabled, Scarf will attempt to automatically find and pair Scarf Companies with CRM Accounts based on text pattern matching.</li> <li>If Auto-Match is disabled, or if no automatic match is found, you can manually match a Scarf Company to the correct CRM Account.</li> </ul>"},{"location":"crm-overview/#syncing","title":"Syncing","text":"<p>Syncing is the process of writing Scarf Company engagement data into the matched CRM Account.</p> <ul> <li>If Auto-Sync is enabled, all matched Scarf Companies will be included in sync operations automatically.</li> <li>If Auto-Sync is disabled, sync operations must be triggered manually.</li> <li>If a company is not matched, it will not be included in any sync.</li> <li>If Automatically Create New Accounts is enabled, any unmatched Scarf Companies will be created as new Accounts in your CRM and included in the sync.</li> </ul>"},{"location":"crm-overview/#unmatching-scarf-companies-from-crm-accounts","title":"Unmatching Scarf Companies from CRM Accounts","text":"<p>You may need to unmatch a company from your CRM in the following cases: -   The wrong CRM account was matched to a Scarf Company, and it needs to be corrected. -   The company is no longer relevant for tracking and should not receive future updates. -   A duplicate or incorrect record was created in the CRM and needs to be removed from the sync process. -   The company structure has changed, and the existing match no longer applies.</p> <p>To unmatch or unsync a Scarf Company from a CRM account: -   Navigate to the <code>Homepage</code> or <code>Insights page</code>. -   Click the <code>CRM Controls</code> button to enable CRM management. -   Use either the <code>Edit</code> button to update the match or the <code>x</code> (Remove) button to unmatch the company.</p> <p>Unmatching a company does not remove previously synced data from the CRM. However, Scarf will no longer attempt to update that record in future syncs.</p>"},{"location":"crm-overview/#monitoring-crm-sync-status","title":"Monitoring CRM Sync Status","text":"<p>While the CRM Connection is established, a history of sync activity is available on your Settings -&gt; Integrations page. The table Recent CRM Sync history provides a summary of the actions performed in each sync.</p> <p>Each configured CRM will have its own Recent CRM Sync history list, allowing you to track sync activity for multiple CRM connections separately.</p> <p>You may also click on <code>View logs</code> for the verbose output of the synchronization run.</p> <p>NOTE: Sync history is retained for 30 days, after which records will be automatically deleted.</p> <p>The Recent CRM Sync History table provides a summary of each synchronization event. It includes the following columns:</p> <ul> <li>Date \u2013 The timestamp of when the sync event occurred.</li> <li>Total \u2013 A breakdown of the actions performed during the sync. This includes:<ul> <li>Created \u2013 The number of new accounts created in your CRM.</li> <li>Synced \u2013 The number of accounts matched and synced with an existing record.</li> <li>Fetched \u2013 The number of account records retrieved from the CRM.</li> <li>Auto-Matched \u2013 The number of companies surfaces by Scarf mapped to one of the fetched CRM accounts.</li> <li>Marked for Sync \u2013 A company surfaced by Scarf set to sync activity to the CRM, either through auto-matching or manual selection in the Scarf Insights page.</li> </ul> </li> <li>Success \u2013 The number of actions that were completed successfully.</li> <li>Failures \u2013 A breakdown of actions that failed, categorized into:<ul> <li>Create \u2013 Number of new accounts that failed to be created in the CRM.</li> <li>Sync \u2013 Number of existing accounts that failed to update.</li> <li>Ambiguous Auto-Matches \u2013 Cases where a company surfaced by Scarf matches multiple CRM accounts, but the system cannot determine which one should receive the Scarf activity.</li> </ul> </li> </ul> <p> </p> <p>For a detailed guide on how to make the most of your CRM integration, check out our CRM Integration Playbook. It walks you through configuring the connection, matching and syncing companies.</p>"},{"location":"custom-telemetry/","title":"Custom telemetry","text":""},{"location":"custom-telemetry/#custom-telemetry-with-scarf-gateway","title":"Custom Telemetry With Scarf Gateway","text":"<p>Note</p> <p>For authenticated bulk imports of custom events collected from an external source, see event importing.</p> <p>Scarf provides you the ability to collect custom telemetry from within your application or code by sending unauthenticated requests to Scarf Gateway for collection and analysis. To enable this you'll need a Scarf account and an Event Collection Package.</p> <p>Once this has been done, you can send telemetry data and associate it with the Scarf package you just created via HTTP requests to your configured endpoint.</p> <p>Event payloads are sent via either pre-configured URL path segments, or by sending query parameters in the request URL. Variables values are currently always interpreted as strings. Learn more about variables here.</p> <pre><code>from scarf import ScarfEventLogger\n\n# Initialize with required endpoint URL\nlogger = ScarfEventLogger(\n    endpoint_url=\"https://your-scarf-endpoint.com\",\n    timeout=5.0  # Optional: Set default timeout in seconds (default: 3.0)\n)\n\n# Send an event with properties\nsuccess = logger.log_event({\n    \"event\": \"package_download\",\n    \"package\": \"scarf\",\n    \"version\": \"1.0.0\"\n})\n\n# Send an event with a custom timeout\nsuccess = logger.log_event(\n    properties={\"event\": \"custom_event\"},\n    timeout=1.0  # Override default timeout for this call\n)\n\n# Empty properties are allowed\nsuccess = logger.log_event({})\n</code></pre>"},{"location":"custom-telemetry/#sdks-and-utilities","title":"SDKs and Utilities","text":"<p>Most of the time, telemetry sent to Scarf is simple enough that leveraging an SDK is not needed, and a single http call from your code is enough. However there are few tools that may be useful depending on the language you are working in:</p> <ul> <li>Python</li> <li>Bash or shell</li> </ul>"},{"location":"custom-telemetry/#real-world-examples","title":"Real world examples","text":"<p>You can find 1k+ real world open source examples of how projects use Scarf telemetry in various languages on GitHub.</p>"},{"location":"custom-telemetry/#java","title":"Java","text":"<pre><code>/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\npublic class TelemetryCollector {\n\nprivate static final String BASE_URL = \"https://sedona.gateway.scarf.sh/packages/\";\nprivate static final AtomicBoolean telemetrySubmitted = new AtomicBoolean(false);\n\npublic static String send(String engineName, String language) {\nString telemetrySubmitUrl = \"\";\nif (!telemetrySubmitted.compareAndSet(false, true)) {\nreturn telemetrySubmitUrl;\n}\ntry {\nString arch = URLEncoder.encode(System.getProperty(\"os.arch\").replaceAll(\" \", \"_\"), \"UTF-8\");\nString os = URLEncoder.encode(System.getProperty(\"os.name\").replaceAll(\" \", \"_\"), \"UTF-8\");\nString jvm =\nURLEncoder.encode(System.getProperty(\"java.version\").replaceAll(\" \", \"_\"), \"UTF-8\");\n\n// Construct URL\ntelemetrySubmitUrl =\nBASE_URL + language + \"/\" + engineName + \"/\" + arch + \"/\" + os + \"/\" + jvm;\n\n// Check for user opt-out\nif (System.getenv(\"SCARF_NO_ANALYTICS\") != null\n&amp;&amp; System.getenv(\"SCARF_NO_ANALYTICS\").equals(\"true\")\n|| System.getenv(\"DO_NOT_TRACK\") != null &amp;&amp; System.getenv(\"DO_NOT_TRACK\").equals(\"true\")\n|| System.getProperty(\"SCARF_NO_ANALYTICS\") != null\n&amp;&amp; System.getProperty(\"SCARF_NO_ANALYTICS\").equals(\"true\")\n|| System.getProperty(\"DO_NOT_TRACK\") != null\n&amp;&amp; System.getProperty(\"DO_NOT_TRACK\").equals(\"true\")) {\nreturn telemetrySubmitUrl;\n}\n\nThread telemetrySubmitThread = createThread(telemetrySubmitUrl);\ntelemetrySubmitThread.start();\n} catch (Exception e) {\n// Silent catch block\n}\nreturn telemetrySubmitUrl;\n}\n//...\n</code></pre>"},{"location":"custom-telemetry/#rust","title":"Rust","text":"<pre><code>// Copyright 2025 RisingWave Labs\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n\n// impl logic to report to Scarf service, containing RW version and deployment platform\npub async fn report_to_scarf() {\nlet request_url = format!(\n\"https://risingwave.gateway.scarf.sh/telemetry/{}/{}\",\nRW_VERSION,\nSystem::name().unwrap_or_default()\n);\n// keep trying every 1h until success\nloop {\nlet res = reqwest::get(&amp;request_url).await;\nif let Ok(res) = res {\nif res.status().is_success() {\nbreak;\n}\n}\ntokio::time::sleep(tokio::time::Duration::from_secs(3600)).await;\n}\n}\n</code></pre>"},{"location":"custom-telemetry/#best-practices-and-recommendations","title":"Best Practices and Recommendations","text":"<ul> <li>Manage user consent via environment variable and any configuration your project already offers. Make it easy for your users to opt in/out by giving them multiple options if possible.</li> <li><code>DO_NOT_TRACK</code> is a common environment variable to check for opt out.</li> <li>Never interrupt the user.</li> <li>Set aggressive timeouts for all network calls for telemetry.</li> </ul>"},{"location":"data-export/","title":"Data Export","text":""},{"location":"data-export/#introduction","title":"Introduction","text":"<p>Scarf provides a robust platform for tracking package downloads and pixel views. The ability to export this data is crucial for analytics, reporting, and integrating with other tools. This guide aims to provide a clear and concise explanation of how to export data from Scarf, what data is exported, and how to make use of any available integrations.</p>"},{"location":"data-export/#prerequisites","title":"Prerequisites","text":"<p>Exporting data from Scarf will only work if you are on a Scarf Basic or Premium Plan.</p>"},{"location":"data-export/#how-to-export-event-data","title":"How to Export Event Data","text":""},{"location":"data-export/#scarf-dashboard","title":"Scarf Dashboard","text":"<p>To export data out of Scarf,</p> <ol> <li>go to the main dashboard and</li> <li>click \"Export packages data\".</li> </ol> <p>This will export all data, for the default period, over the past month.</p> <p></p> <p>The data you can export from Scarf includes all events (defined as package downloads and pixel views) from every user that has interacted with your Scarf-enabled artifacts (packages and pixels). Upon clicking \"Export packages data\", this data will download as a .csv file.</p>"},{"location":"data-export/#scarf-api","title":"Scarf API","text":"<p>You can also export this data using the Scarf API.</p>"},{"location":"data-export/#what-data-is-exported","title":"What Data is Exported","text":""},{"location":"data-export/#export-fields","title":"Export Fields","text":"<p>The event data export includes the following data fields</p> name type description id <code>text</code> This uniquely identifies the event (pixel view or package download) that occurred. type <code>text</code> This categorizes the type of event that occurred (e.g. pixel-fetch, manifest-fetch, binary-download, etc.). package <code>text</code> For Scarf package downloads, this specifies which package has been downloaded. pixel <code>text</code> For Scarf page views, this specifies which pixel has been downloaded. version <code>text</code> For Scarf package downloads, this specifies which version of the package has been downloaded. time <code>timestamp</code> This refers to the time in UTC that the event occurred. referer <code>text</code> For Scarf pixel views, this refers to the page that was viewed. user_agent <code>text</code> This refers to the User-Agent, which provides information around the method of installation, often including information such as operating system, device, browser, architecture, and client. variables <code>text</code> This refers to any custom-specified variables that you might use Scarf to track in file package downloads. origin_id <code>text</code> This uniquely identifies the user (through a specific device) who has interacted with a Scarf event. origin_latitude <code>numeric</code> This is the latitude of the location Scarf is able to identify for the event. origin_longitude <code>numeric</code> This is the longitude of the location Scarf is able to identify for the event. origin_country <code>text</code> This is the country of the location Scarf is able to identify for the event. origin_city <code>text</code> This is the city of the location Scarf is able to identify for the event. origin_state <code>text</code> This is the state of the location Scarf is able to identify for the event. origin_postal <code>text</code> This is the postal code (ZIP code, in the US) of the location Scarf is able to identify for the event. origin_connection_type <code>text</code> This categorizes the type of IP address Scarf is able to identify (e.g. business, isp, hosting, etc.). origin_company <code>text</code> If Scarf is able to associate the event with a known business entity, that business entity is listed here. origin_domain <code>text</code> If Scarf is able to associate the event with a known business entity, that business entity's web domain address is listed here. dnt <code>boolean</code> If the user includes a DNT request in their header, that is logged here and they will not be tracked. confidence <code>numeric</code> The probability of correct identification of the data. endpoint_id <code>text</code> This uniquely identifies the public-facing device that has interacted with a Scarf event. Unlike origin_id, it is notably not sensitive to changes in device information like client, user agent, etc. mtc_quota_exceeded <code>boolean</code> A value of <code>true</code> indicates the company information from the event data row was scrubbed due to exceeding the MTC limit."},{"location":"data-export/#how-to-export-aggregate-data","title":"How to Export Aggregate Data","text":"<p>The documentation for exporting aggregates can be found in Export aggregates. Here's an example curl request to download aggregate data. The output is newline delimited json. <pre><code>curl -o {filename}.jsonl \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: application/x-ndjson\" \\\n\"https://api.scarf.sh/v2/packages/{owner}/aggregates?start_date={start_date}&amp;end_date={end_date}&amp;breakdown=by-company\"\n</code></pre></p>"},{"location":"data-export/#how-to-export-company-data","title":"How to Export Company Data","text":"<p>The documentation for exporting company data that is rolled up with a daily interval can be found in Export Company Data</p> <p>Here's an example curl request to download company rolled up data. <pre><code>curl -o company-rollup.csv \\\n-H \"Authorization: Bearer {token} \\\n    -H \"Content-Type: text/csv\" \\\n    https://api.scarf.sh/v2/packages/{owner}/company-rollup\n</code></pre></p> <p>The company data export includes the following data fields.</p> name type description company_name <code>text</code> Name of the company company_domain <code>text</code> Domain of the company. Eg. scarf.sh funnel_stage <code>text</code> Stage of a company's journey in using your software total_events <code>numeric</code> Count of total events unique_sources <code>numeric</code> Number of distinct sources of traffic that comprise the total event count from this organization. first_seen <code>text</code> Date of when the first event occured last_seen <code>text</code> Date of when the last event occured company_linkedin_url <code>text</code> A company's LinkedIn link company_industry <code>text</code> A company's industry. Eg. Tech, Government, etc. company_size <code>text</code> A company's approximated employee count company_country <code>text</code> A company's country location company_state <code>text</code> A company's state location interest_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the interest funnel_stage investigation_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the investigation funnel_stage experimentation_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the experimentation funnel_stage ongoing_usage_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the ongoing usage funnel_stage inactive_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the inactive funnel_stage scarf_url <code>text</code> <code>format: uri</code> URL to the Scarf dashboard page for this company's activity package_totals <code>text</code> A string of <code>&lt;package_name&gt;=&lt;download total&gt;</code> pairs, in query parameter format (i.e., <code>&amp;</code> delimited) tracking_pixel_totals <code>text</code> A string of <code>&lt;pixel_name&gt;=&lt;view total&gt;</code> pairs, in query parameter format (i.e., <code>&amp;</code> delimited)"},{"location":"data-export/#how-to-export-company-events","title":"How to Export Company Events","text":"<p>The documentation for exporting company events can be found in Export Company Events. Here's and exampe curl request to download company events data. <pre><code>curl -o company-events.csv \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: text/csv\" \\ \n\"https://api.scarf.sh/v2/companies/{owner}/{domain}/events?start_date={start_date}&amp;end_date={end_date}\"\n</code></pre> The fields for this export can be found here</p>"},{"location":"data-export/#integrations","title":"Integrations","text":""},{"location":"data-export/#scarf-to-postgresql","title":"Scarf to PostgreSQL","text":"<p>GitHub: https://github.com/scarf-sh/scarf-postgres-exporter</p>"},{"location":"data-export/#overview","title":"Overview","text":"<p>The Scarf to PostgreSQL Exporter is a script designed to pull down your raw Scarf data and send it into a PostgreSQL database. This script is intended to be run as a daily batch job. It provides an automated way to backfill and update your PostgreSQL database with Scarf's enhanced data.</p>"},{"location":"data-export/#prerequisites_1","title":"Prerequisites","text":"<ul> <li><code>psql</code> must be installed and available in your environment (or use the Docker container with everything you need). </li> <li>A Scarf Account.</li> <li>Your Scarf API token. You can find your API Token from your user settings page.</li> </ul>"},{"location":"data-export/#settings","title":"Settings","text":"<p>The following environment variables are required:</p> <ul> <li><code>SCARF_API_TOKEN</code>: Your Scarf API access token.</li> <li><code>SCARF_ENTITY_NAME</code>: Your Scarf username or the name of your organization.</li> <li><code>PSQL_CONN_STRING</code>: The PostgreSQL connection string.</li> </ul> <p>optional</p> <ul> <li><code>BACKFILL_DAYS</code>: Number of days to backfill data. Defaults to 31 if not set.</li> </ul>"},{"location":"data-export/#getting-started","title":"Getting Started","text":"<p>For more details, you can visit the GitHub repository.</p>"},{"location":"data-export/#future-integrations","title":"Future Integrations","text":"<p>Integrations are in development, if you have particular data sources you'd like Scarf to integrate with, we'd love to hear from you.</p>"},{"location":"data-export/#daily-scheduled-exports","title":"Daily Scheduled Exports","text":"<p>In your organization settings, fill in the details for the export.</p> <p>Scheduling an export can also be done with our REST endpoint https://api.scarf.sh/v2/exports/{owner}/schedule-export</p> <p>We can export both raw events and company rollups.</p> <p>After scheduling the export, we send a test file named <code>scarf-test.csv</code> to verify connectivity to your bucket. This file will only contain CSV headers. Once connectivity is confirmed, the export process will automatically begin sending files to your bucket every day. Typically, exports run in the evening UTC for the previous days' data.</p>"},{"location":"data-export/#aws-s3-integration","title":"AWS S3 Integration","text":"<p>Setting up your S3 account</p> <p>The S3 uri that you submit will be considered as the bucket name. Do not specify an object key. The service will generate the object key with the format <code>&lt;events|company-rollups&gt;-scarf-export-&lt;start date&gt;-&lt;end date&gt;.csv</code>.</p> <p>Create a policy that states we can assume a role. Here's an example of that policy. This example is a highly permissive role. If you want to customize the role, please refer to the proper AWS documentation. <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"sts:AssumeRole\",\n\"sts:*\"\n],\n\"Resource\": \"*\"\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:*\"\n],\n\"Resource\": [\n\"arn:aws:s3:::&lt;bucket-name&gt;/&lt;folder-a&gt;/&lt;subfolder-a&gt;/*\"\n]\n}\n]\n}\n</code></pre> After creating the policy, create a role and attach the policy. Once you've created the role, you should have an ARN that looks like this <pre><code>arn:aws:iam::&lt;account-id&gt;:role/&lt;role-name&gt;\n</code></pre> The easiest way to create a role is to pick \"AWS Account\" in the \"Select trusted entity\" section. Then in the \"An AWS Account\", pick \"Another AWS Account\". This will ask for an account aws account id. This is where you will put in scarf's account id <code>032190491485</code>.</p> <p>After creating the role, go to the \"Trust relationships\" and add the following trust policy <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::032190491485:user/production-v2-scarf-server\"\n},\n\"Action\": \"sts:AssumeRole\"\n}\n]\n}\n</code></pre></p> <p>If you want to use an <code>ExternalId</code>, your trust policy should be modified to look like the example below: <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::032190491485:user/production-v2-scarf-server\"\n},\n\"Action\": \"sts:AssumeRole\",\n\"Condition\": {\n\"StringEquals\": {\n\"sts:ExternalId\": \"&lt;can be any string&gt;\"\n}\n}\n}\n]\n}\n</code></pre></p> <p>The ARN role is what you will need in the <code>arn_role</code> api field.</p> <p>This is not an exhaustive documentation of how to setup a shared s3 bucket. Please refer to the AWS documentation for more information.</p>"},{"location":"data-export/#google-storage-integration","title":"Google Storage Integration","text":"<p>Before going through the steps of setting up an integration with scarf, ensure your google cloud account has <code>Service Account Credentials API</code> enabled. We will be using service account impersonation so we can integrate with your google account.</p> <p>Create a service account. You can can do this by following these steps.</p> <ol> <li>Go to the <code>IAM &amp; Admin</code> page.</li> <li>Select <code>Service Accounts</code>.</li> <li>Click on <code>+ CREATE SERVICE ACCOUNT</code>.</li> <li>Fill in the details. </li> <li>Grant the service account with the following roles:<ul> <li>Storage Object User</li> </ul> </li> <li>Click done, and you should be done creating the service account \ud83c\udf89</li> </ol> <p>After creating the service account, grant scarf access to that service account by doing the following.</p> <ol> <li>Select the service account.</li> <li>Under the <code>PERMISSIONS</code> tab, you should see <code>GRANT ACCESS</code>. Click on it.</li> <li>After clicking <code>GRANT ACCESS</code>, you should see an input box for <code>New principals</code>.</li> <li>Add our account <code>storage@scarf-integration.iam.gserviceaccount.com</code>.</li> <li>Grant the scarf account the following role:<ul> <li>Service Account Token Creator</li> </ul> </li> </ol> <p>We will be streaming the content of the exports in chunks and using google storage's compose api to stitch all the chunks in a file. So for a brief moment you might see multiple temporary objects in the bucket you have provided us.</p>"},{"location":"event-import/","title":"Importing Events","text":"<p>See API Docs here: api-docs.scarf.sh/v2.html#tag/External-event-import</p> <p>You can bring your events from other applications and platforms into Scarf with the Event Import API. Your imported events will be enriched by Scarf asynchronously, and your enriched data will be available through the app and the Data Export.</p> <p>We provide three main ways to import events:</p> <ul> <li>Importing into a single package</li> <li>Importing into a single pixel</li> <li>Importing into multiple packages and pixels by providing IDs in each row</li> </ul> <p>Warning</p> <p>The Event Import system looks for fields prefixed with <code>$</code> as specific pre-defined fields which may impact the behavior of how the event is imported. Some <code>$</code> fields are required. For instance, you will be required to provide date-time using the <code>$time</code> field at minimum (ISO or timestamp), and you may want to provide a unique identifier for each event using <code>$unique_id</code> . Note that this <code>$unique_id</code> will override previous events if reused. For importing multiple packages and pixels, you will have to provide the relevant ID through the <code>$package</code> and <code>$pixel</code> fields. Any fields that are not prefixed with a <code>$</code> are treated as custom variables that will not impact any data processing otherwise. See the API docs for more details: https://api-docs.scarf.sh/v2.html#tag/External-event-import/operation/importEvents</p> <p>Danger</p> <p>The Event Import API is meant to handle large, bundled imports, and is limited to 15 concurrent imports. Past this limit, you will get a 422: too many active imports error. To avoid running into this problem, make sure to batch your imports if you have automation to bring data into Scarf.</p>"},{"location":"event-import/#getting-started","title":"Getting Started","text":"<p>To get started, create packages and pixels in your account to import data into them. You will need to get IDs from the packages and pixels you want to import data into.</p>"},{"location":"event-import/#importing-into-a-single-package","title":"Importing into a single package","text":"<p>You will need to get the ID of your package from Scarf from the app or the List packages endpoint. Once you have your ID, you can start sending your events to Scarf from our Package Event Import endpoint.</p> <p>Info</p> <p>You may want to save the ID returned from the Imports API, in case you need to cancel the import or see its status later. You can also call the imports list endpoint to get a list of your imports and their statuses even if you don\u2019t save the ID from here.</p> <p>Example</p> <p>api.scarf.sh/v2/packages/{owner}/{package_id}/import</p> <p>events.ndjson</p> <pre><code>{\"$remote_address\":\"152.241.796.177\",\"$time\":\"2024-06-04T00:00:00Z\",\"$unique_id\":\"c20b1271-fb3f-abfa-df12-ef3cda4b2aa0\"}\n{\"$remote_address\":\"600.188.717.651\",\"$time\":\"2024-06-01T00:00:00Z\",\"$unique_id\":\"9053a19a-15a9-3695-bd37-b055a45949c1\"}\n{\"$remote_address\":\"665.921.984.205\",\"$time\":\"2024-06-25T00:00:00Z\",\"$unique_id\":\"09b5b69a-0af0-8002-2c2b-39df3d5685a4\"}\n</code></pre> <p>import-to-package.bash</p> <pre><code>#!/usr/bin/env bash\n\ncurl -v \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: application/ndjson\" \\\n-X POST https://api.scarf.sh/v2/packages/YourOrg/abc01234-0000-0000-0000-000000000000/import \\\n--data-binary @events.ndjson\n</code></pre> <p>This will import three events into the package with ID <code>abc01234-\u2026</code> .</p>"},{"location":"event-import/#importing-into-multiple-packages-and-pixels","title":"Importing into multiple packages and pixels","text":"<p>Importing into multiple packages and pixels is the same as above, but require IDs from your packages and pixels. Make sure to include them in your events when your bring them into Scarf through the Multi-Artifact Event Import endpoint.</p> <p>Example</p> <p>api.scarf.sh/v2/{owner}/import</p> <p>events.ndjson</p> <pre><code>{\"$package\":\"970493a1-4ca0-4a4d-a085-fdce578e5a08\",\"$remote_address\":\"152.241.796.177\",\"$time\":\"2024-06-04T00:00:00Z\",\"$unique_id\":\"c20b1271-fb3f-abfa-df12-ef3cda4b2aa0\"}\n{\"$package\":\"970493a1-4ca0-4a4d-a085-fdce578e5a08\",\"$remote_address\":\"600.188.717.651\",\"$time\":\"2024-06-01T00:00:00Z\",\"$unique_id\":\"9053a19a-15a9-3695-bd37-b055a45949c1\"}\n{\"$package\":\"970493a1-4ca0-4a4d-a085-fdce578e5a08\",\"$remote_address\":\"665.921.984.205\",\"$time\":\"2024-06-25T00:00:00Z\",\"$unique_id\":\"09b5b69a-0af0-8002-2c2b-39df3d5685a4\"}\n</code></pre> <p>import-multiple-artifacts.bash</p> <pre><code>#!/usr/bin/env bash\n\ncurl -v \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: application/ndjson\" \\\n-X POST https://api.scarf.sh/v2/YourOrg/import\n  --data-binary @events.ndjson\n</code></pre> <p>This will import three events into the package with ID <code>abc01234-\u2026</code> .</p>"},{"location":"event-import/#importing-compressed-files","title":"Importing compressed files","text":"<p>Compress your file by doing the following command <pre><code>gzip -k events.ndjson\n</code></pre> This will output <code>events.ndjson.gz</code> and retain the uncompressed file.</p> <p>Here's an example of how to import a compressed file via curl. Reference the compressed file and make sure to specify the <code>Content-Encoding</code> header to <code>gzip</code> so our api will recognize that a compressed file is being imported. <pre><code>#!/usr/bin/env bash\n\ncurl -v \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: application/ndjson\" \\\n-H \"Content-Encoding: gzip\" \\\n-X POST https://api.scarf.sh/v2/packages/YourOrg/abc01234-0000-0000-0000-000000000000/import \\\n--data-binary @events.ndjson.gz\n</code></pre></p>"},{"location":"event-import/#checking-import-status","title":"Checking Import Status","text":"<p>To check the status of your imports, you can use the Event Imports List endpoint.</p> <p>Example</p> <p>api.scarf.sh/v2/imports/{owner}</p> <p><code>curl [...] \"https://api.scarf.sh/v2/imports/YourOrg\"</code></p> <pre><code>{\n\"event_imports\": [\n{\n\"created_at\": \"2023-08-04T13:58:26.021037Z\",\n\"error_log_sample\": [\n{\n\"class\": \"error\",\n\"human_friendly_message\": \"Not a valid JSON object\",\n\"line\": 1,\n\"type\": \"failed-to-decode\"\n}\n],\n\"events_failed_to_import\": 1,\n\"events_successfully_imported\": 0,\n\"events_total\": 1,\n\"id\": \"0c4f966c-b715-497a-83e2-467254c95e40\",\n\"owner\": \"YourOrg\",\n\"status\": \"done\",\n\"updated_at\": \"2023-08-04T13:58:26.784432Z\",\n\"warning_log_sample\": []\n}\n]\n}\n</code></pre> <p>Alternatively, you can go to the Imports page in your organization settings to see a history of imports and see sample of warning and error logs:</p> <p></p>"},{"location":"event-import/#cancelling-imports","title":"Cancelling Imports","text":"<p>If you need to cancel an existing import, you can reference the import by its ID and call the Abort Event Import endpoint.</p> <p>If you haven\u2019t saved the ID from the import request, you can still find it from the Event Imports List endpoint.</p> <p>Example</p> <p>api.scarf.sh/v2/imports/{owner}/{event_import_id}/abort</p> <pre><code>$ curl [\u2026] -I -X POST \"https://api.scarf.sh/v2/imports/YourOrg/abc01234-0000-0000-0000-000000000000/abort\"\nHTTP/2 204\n</code></pre>"},{"location":"funnel-stages/","title":"Open Source Adoption Funnel Stages","text":"<p>Scarf analyzes how companies interact with your open-source project to infer their progress toward adopting it. Funnel Stages represent the portion of the user journey that best describes any given company or lead, from the moment they learn of your project, to when they deploy it to production, and beyond.\u00a0</p> <p>All paid subscribers and active trial participants will see a Funnel Stage on Company Views/Downloads in your Package and Pixel Analytics. Funnel Stages begin at the most basic level with interest, increasing all the way to ongoing usage.</p> <p></p> <p>As events by a user/organization occur, such as views or downloads, Scarf assigns point values to them. Those points add up over time as a user moves into different stages of the funnel. The frequency of activity is also considered, and points can be removed as the time between activities increases and the perceived interest or likelihood to adopt decreases.\u00a0</p> <p>Scarf\u2019s funnel stages are as follows:</p>"},{"location":"funnel-stages/#interest","title":"Interest","text":"<p>A company enters this stage following initial events such as viewing your documentation, README, or site (pixel activity only - a download would trigger the investigation stage). \u00a0\u00a0</p>"},{"location":"funnel-stages/#investigation","title":"Investigation","text":"<p>Enough activity has occurred for us to suspect the user/organization is actively investigating your OSS. This stage includes the occurrence of multiple events such as at least one package download with multiple docs views or at least two weeks of consecutive pixel view activity, and the company has been active in the last 30 days.\u00a0</p>"},{"location":"funnel-stages/#experimentation","title":"Experimentation","text":"<p>Sufficient activity has occurred for us to suspect the company is actively trying your OSS, but might not be relying on it in a production workload yet. Events such as multiple downloads and page views will have occurred over 30 days, or a single download and multiple page views over 60 days.\u00a0The origanization may be in the development with your OSS, or prototyping, or running internal tests. We don't yet have enough evidence to make stronger conclusions about production usage.</p>"},{"location":"funnel-stages/#ongoing-usage","title":"Ongoing Usage","text":"<p>By this stage, Scarf has enough data to conclude the company is using your software in an ongoing manner, potentially in a production environment.  Companies in this stage may be ready to become paying customers and should be moved into your sales/marketing pipeline where available. For non-commercial open-source projects, companies in this stage may be good sponsorship targets or valuable advocates in the community. These companies will have event activity over the course of the past 90 days, such as continued downloads or views.</p>"},{"location":"funnel-stages/#inactive","title":"Inactive","text":"<p>Companies may move into an inactive stage when activity drops off and does not resume over 60 or more days. If activity resumes, the company will return to the last active stage.\u00a0</p>"},{"location":"funnel-stages/#recommended-sort","title":"Recommended Sort","text":"<p>The Recommended Sort reorders the list of companies in the activity table in descending order, first by their point value, then by number of events, and finally by most recent to oldest last seen value. This sort option lets you view the companies most worthy of your attention first.\u00a0</p> <p></p>"},{"location":"funnel-stages/#company-journey","title":"Company Journey","text":"<p>When selecting a company to view in greater detail from any of the Company analytics charts, Administrators will see greater detail within the Company Journey. The company\u2019s current funnel stage will be displayed in the top left, next to STATUS. Hover over the graphical calendar in the Company Journey to see details of the views and downloads that occurred over time. Below the graphical calendar are aggregated views of the total activity within each stage, including the current stage.\u00a0</p> <p></p>"},{"location":"funnel-stages/#event-importance","title":"Event Importance","text":"<p>Event Importance allows you to determine the weight that certain events carry over others. For instance, a download should carry more weight than a page view on your public website as it shows higher interest. This importance can be defined when setting up a new pixel or package and can be edited anytime. The importance will default to medium.\u00a0</p> <p>You\u2019ll see the Event Importance noted on the Events detail charts.\u00a0</p> <p></p> <p>Use the Event Importance slider to set or edit the importance of a Package or Pixel.\u00a0</p> <p></p>"},{"location":"funnel-stages/#using-your-scarf-funnel-stage-data","title":"Using Your Scarf Funnel Stage Data","text":"<p>Scarf's data combines lead scoring's best features with intent data. Real-time activity highlights the companies actively researching and testing your open-source software. This data facilitates operationalizing the usage and intent data provided by your Scarf Gateway.\u00a0Utilize the data to track trends in usage over time to indicate your ideal customer profile, highlight opportunities and risks, such as early indicators of potential churn, or documentation that needs more frequent updating.</p> <p>Sudden and/or unexpected changes in activity levels or types may indicate a company looking to make a change. While this change may be good or bad, it is worthy of attention and investigation. Key examples include:</p> <ul> <li> <p>A previously consistent user goes inactive</p> </li> <li> <p>An existing paying customer of yours becomes very active with OSS, potentially indicating a downgrade before it actually happens</p> </li> <li> <p>You begin to see more traffic to documents explaining data export by certain users</p> </li> </ul>"},{"location":"funnel-stages/#go-even-further-with-your-outreach","title":"Go Even Further with Your Outreach","text":"<p>If you\u2019re interested in going beyond the company-level data that Scarf provides in our OQLs and Funnel Stages, Scarf can help you procure a list of individuals with contact information that may be good target leads at your target companies. If interested, please contact Scarf Support to discuss our Lead Generation services.\u00a0</p>"},{"location":"gateway/","title":"Scarf Gateway","text":""},{"location":"gateway/#overview","title":"Overview","text":"<p>Scarf Gateway is a service that sits in front of your existing software hosting platform(s), acting as a single access-point to all of your artifacts, regardless of where they are actually hosted. By making it easy to host content from your own domain, Scarf Gateway decouples your distribution from your hosting provider and provides in-depth download analytics.</p> <p>Suppose you maintain a Docker container image <code>acme/rocket-skates</code> on Docker Hub. Your users would normally pull your container image from Docker hub directly (<code>docker pull acme/rocket-skates</code>.) Using Scarf, they would pull from Scarf Gateway using your private domain (<code>docker pull docker.acme.com/acme/rocket-skates</code>.) Important analytics are recorded and shared with you while you are using Scarf and you may change your hosting providers at any time without changing your container image name or documentation.</p> <p>Your users will always be using your domain to pull your Docker container images. Your Docker container images can stay on their current hosting provider, but will be served through your own domain, e.g.:</p> <pre><code># Make your existing container available through your own domain\n$ docker pull docker.acme.com/acme/rocket-skates\n\n# Scarf provides a domain too if you'd prefer to use ours\n$ docker pull acme.docker.scarf.sh/acme/rocket-skates\n</code></pre> <p>Data insights about your Docker container image's downloads can be found in your Scarf Dashboard. From there, you can also manage Scarf Gateway configuration, access controls, and more.</p>"},{"location":"gateway/#configuring","title":"Configuring","text":""},{"location":"gateway/#scarf-package-entries","title":"Scarf Package Entries","text":"<p>Everything that is served and tracked via Scarf Gateway needs a corresponding package entry on scarf.sh. Configuration, analytics, and permissions are all done at the level of a package, or single repository. <code>rocket-skates</code>, <code>acme/rocket-skates</code> are all valid package entries. Because packages can seamlessly change their hosting provider, hostnames (e.g. <code>gcr.io</code>) are not part of the package identifier on Scarf (e.g. <code>acme/rocket-skates</code> and not <code>gcr.io/acme/rocket-skates</code>.)</p> <p>To create your package entry, click \"New Package\" in the navbar in your Scarf dashboard. Then select the corresponding package type for your artifact.</p>"},{"location":"gateway/#container-image-packages","title":"Container Image Packages","text":"<p>Scarf Gateway configuration for a Docker container image entry has two main considerations:</p> <ul> <li>Backend URL: This refers to where your container is actually hosted, the location where Scarf will direct requests to pull the container. Scarf will ask for your container's current pull command. This could be <code>rocket-skates</code>, <code>acme/rocket-skates</code> (implicitly specifying Docker Hub as the hosting provider, <code>registry-1.docker.io/acme/rocket-skates</code>), or a fully qualified container image name <code>docker.acme.come/acme/rocket-skates</code>. You can modify this backend URL attribute later, and your user's Docker pulls will be instantly moved over to the new destination without having to communicate anything to them.</li> <li>Domain: This can be your own domain, or a Scarf-supplied domain, of the form <code>&lt;username&gt;.docker.scarf.sh</code>. By default your Scarf domain will be used if this field is left empty. Note that this will be part of your Docker pull command for your users. While you can update this domain, updating your public domain is a breaking change for any users on the current domain! Edit this value with caution.</li> </ul> <p>If you elect to use your own domain, you'll need to add a CNAME for that domain to <code>gateway.scarf.sh</code>. Additionally we require you to verify your ownership of the domain by setting a TXT with a value that Scarf provides upon package creation. See your DNS provider's instructions for how to add CNAME and TXT records.</p> <p>See Figure 0 to see how these pieces fit together visually.</p>"},{"location":"gateway/#python-packages","title":"Python Packages","text":"<p>Scarf Gateway configuration for a Python package entry has three main considerations:</p> <ul> <li>pip Command: This is the current pip command used to install your package. For packages on PyPI.org, this will be of the form <code>pip install my-pkg</code> and will include the <code>--extra-index-url https://my-python-project-domain.com</code> if your package is hosted elsewhere. This defines the location where the users will be redirected to when installing your package.</li> <li>Domain: This can be your own domain, or a Scarf-supplied domain, of the form <code>&lt;username&gt;.gateway.scarf.sh</code>. By default, your Scarf domain will be used if this field is left empty.</li> </ul>"},{"location":"gateway/#installing-python-packages-via-requirementstxt","title":"Installing Python packages via requirements.txt","text":"<p>Add the --extra-index-url option at the top of your requirements.txt:</p> <pre><code>--extra-index-url https://my-python-project-domain.com/simple/\nmy-pkg==0.0.1\n</code></pre> <p>NOTE: We have noticed indeterminate behavior in some versions of Pip that have resulted in the public registry being used for download regardless of the --extra-index-url addition.</p> <p>If you elect to use your own domain, you'll need to add a CNAME for that domain to <code>gateway.scarf.sh</code>. Additionally we require you to verify your ownership of the domain by setting a TXT with a value that Scarf provides upon package creation. See your DNS provider's instructions for how to add CNAME and TXT records.</p>"},{"location":"gateway/#file-packages","title":"File Packages","text":"<p>File Packages on Scarf are a flexible and low-level package type that can track visits and downloads on arbitrary URLs. File packages were originally created to track published tar balls, but it has since expanded to many other use cases and will likely be renamed in future versions of Scarf. You can think of File Packages as a powerful and fully customizable link shortener. Common use cases include:</p> <ul> <li>Tracking downloads of GitHub release artifacts</li> <li>Tracking downloads of every artifact on your company/project \"downloads\" page</li> <li>Tracking downloads of Homebrew packages from a tap/formula that you control</li> <li>Sending custom telemetry or other events from your application</li> <li>Tracking and attributing visits to marketing and sales content on your site.</li> </ul> <p></p> <p>Scarf Gateway configuration for a file package entry has a few main considerations:</p> <ul> <li>Domain: Just like Docker container images, you may choose to use your own domain(s) for serving files. You may also choose to use <code>&lt;username&gt;.gateway.scarf.sh</code> provided by default by Scarf. Remember, if you elect to use your own domain, you'll need to add a CNAME for that domain to <code>gateway.scarf.sh</code> as well as verify ownership of that domain.</li> <li>Incoming Path: This refers to where a path on a given domain where Scarf will direct requests to fetch a file asset. This could be static path like <code>/downloads/rocket-skates.tar.gz</code> or a template path with variables like <code>/files/{version}/{platform}/rocket-skates-{platform}-{version}.tar.gz</code>. You may use variables in your incoming path as specified in RFC 6570. You can modify a path value later, but be careful to communicate to your users because this would be a breaking change. Read more about variables here.</li> <li>Outgoing URL: This is an optional full URL to your asset on your HTTP/S hosting provider. It is a template (or static) URL that may also use any variables defined in the Incoming Path. For example <code>https://besthostingprovider.com/acme/{platform}/rocket-skates-{version}.tar.gz</code>. If an Outgoing URL is not provided, the Gateway will return 200 with no redirect.</li> <li>Catch-all redirects: Select this option if you intend to configure a domain-level redirect with your File Package (ie, redirecting <code>site.com/*</code> -&gt; <code>anothersite.com/*</code>).</li> </ul> <p>See Figure 3 to see how these pieces fit together visually.</p>"},{"location":"gateway/#variables","title":"Variables","text":"<p>Scarf Gateway supports dynamic URL routing through the use of variables, enabling flexible and scalable management of downloads across various versions, platforms, and configurations.</p> <p>Variables are any string denoted within curly braces <code>{}</code> or in the URL's query parameters and can be incorporated into the incoming-path and outgoing-url fields of your package configuration. For example:</p> <pre><code>\"incoming-path\": \"/project/{platform}/{version}/file.tar.gz\",\n\"outgoing-url\": \"https://example.com/downloads/{platform}/project-{version}.tar.gz\"\n</code></pre> <p>In this configuration:</p> <p>A request to <code>https://yourorg.gateway.scarf.sh/project/linux-arm64/1.2.3/file.tar.gz</code> would be redirected to <code>https://example.com/downloads/linux-arm64/project-1.2.3.tar.gz</code>, with <code>version = 1.2.3</code> and <code>platform = linux-arm64</code> stored.</p> <p>Variables are parsed by in URLs by Scarf as defined by RFC 6570. This means that variables can span multiple segments of a path with a <code>+</code> prefix, for instance:</p> <pre><code>\"incoming-path\": \"/foo/{+path}\",\n\"outgoing-url\": \"https://example.com/downloads/foo/{+path}\"\n</code></pre> <p>would route <code>https://yourorg.gateway.scarf.sh/foo/a/b/c</code> to <code>https://example.com/downloads/foo/a/b/c</code> with <code>path = a/b/c</code></p> <p>Query parameters are also automatically interpreted as variables for analytics, though they do not affect gateway redirection behavior. The following would send <code>a=b</code> and <code>b=c</code>, regardless of any pre-configured variables in the URL template.</p> <pre><code>https://yourorg.gateway.scarf.sh/foo?a=b&amp;b=c\n</code></pre> <p>Best Practices - Route Structuring: Place fixed path segments before variables to ensure clear and unambiguous routing. For instance, prefer /project/{version}/file.tar.gz over /{project}/{version}/file.tar.gz. - Version Management: Utilize variables like {version} to handle multiple versions without creating separate routes for each. This approach simplifies updates and maintenance. - Platform Differentiation: Incorporate variables such as {os} or {arch} to manage platform-specific downloads efficiently.</p> <p>Analytics Granularity: Variables enable detailed analytics in the Scarf dashboard, allowing you to track downloads per version, platform, or other defined segments.</p>"},{"location":"gateway/#variable-defaults-and-overrides","title":"Variable defaults and overrides","text":"<p>When Scarf processes events like a Docker download, it will automatically pull out special information like the system <code>platform</code> or the <code>version</code>/<code>tag</code>. The same applies for extracting the <code>page</code> when a user views a page with a Scarf pixel. These system-recognized variables are treated in specific ways by Scarf, unlike arbitrary variables which are custom-defined and have no special meaning to how Scarf processes your event data.</p> <p>For lower-level package types like File Packages and Event Collection Packages, Scarf will look for system-recognized variables that can be populated by using specific variable names by default, or you can configure them directly by setting a custom variable override.</p> Default variable name Usage and details <code>page</code> The page that was viewed. By default, Scarf uses the <code>referer</code> header in the HTTP request. However, when rendered on sites like GitHub, sending up <code>page</code> explicitly is useful to work around this behavior. <code>platform</code> Platform of the client behind the download and event. Scarf has a known set of recognized platforms: - <code>macos</code>- <code>darwin</code>- <code>linux</code>- <code>windows</code>- <code>ios</code>- <code>android</code>- <code>aix</code>- <code>freebsd</code>- <code>openbsd</code>- <code>sunos</code>- <code>unknownplatform</code>- <code>allplatforms</code> <code>version</code> The artifact/package version downloaded/used"},{"location":"gateway/#event-collection-packages","title":"Event Collection Packages","text":"<p>Event collection packages are a general package type for collecting telemetry from your code or processing bulk imports of events from an external source. They are equivalent to a <code>file package</code> without a redirect. Scarf will always respond with a 200 to denote the event was successfully stored, rather than a 302 like other package types.</p> <p>If you have a specific schema of data you are expecting to send, you can still configure an incoming path pattern with variables in advance, or just use query parameters to dynamically send any fields you wish.</p>"},{"location":"gateway/#how-it-works","title":"How it works","text":"<p>When a user requests a Docker container image through Scarf, Scarf simply issues a redirect response, pointing to whichever hosting provider you've configured for your container. Certain container runtimes do not handle redirects appropriately during authentication (which is required even for anonymous pulls), and, in those cases, Scarf will proxy the request to the host instead of redirecting. For a visualization of the system from the end-user's perspective, see Figure 1. For an overview of the entire system, Figure 2.</p> <p>When a user requests a file through Scarf, Scarf simply issues a redirect response, pointing to whichever hosting provider you've configured for your file. For a visualization of the system from the end-user's perspective, see Figure 4. For an overview of the entire system, Figure 5.</p> <p>Dashboard and Data Access</p> <p>Your package's usage data will be made available to you in your Scarf dashboard. You can grant others access to your package's usage data as well from your package details page. Current permission levels supported are:</p> Access Level Description Owner Can read all package-level data, edit package configuration, and grant access to other members Admin Can read all package-level data, edit package configuration, and grant access to other members (but can't remove other admins) Member Can read all package-level data"},{"location":"gateway/#docker-packages-defining-a-container-pull","title":"Docker Packages: Defining a container pull","text":"<p>Scarf defines a pull based on how Docker Hub defines them for the purposes of their rate-limiting functionality.</p> <p>A pull is defined as one or more <code>GET</code> requests on hosting provider manifest URLs (<code>/v2/*/manifests/*</code>). <code>HEAD</code> requests are not counted as a pull.</p> <p>Note that even if a client downloads the blobs that comprise any given container, the container's manifest file may already be cached on the client, meaning the download would not be counted in Scarf's analytics. Future versions of Scarf's data processing pipelines will be more intelligent and will track things like partial downloads, blob fetches, etc.</p>"},{"location":"gateway/#security","title":"Security","text":"<p>All interactions through Scarf Gateway occur over HTTPS. Scarf Gateway will procure a valid TLS certificate via LetsEncrypt, and perform TLS termination for the traffic. Scarf Gateway in turn will issue a redirect for the request, or proxy the request to the hosting provider.</p>"},{"location":"gateway/#do-not-track","title":"Do Not Track","text":"<p>Our gateway respects the HTTP Headers as defined in DNT and GPC. If you send an HTTP request to our Scarf Gateway with the HTTP header \"DNT=1\" or \"Sec-GPC=1\", we will not count your request in our statistics nor will we lookup your IP address to determine if you are a business. Basically, it will be as if you didn't request anything from our gateway but we will still serve the content to you.</p> <p>Please note that this behavior works for all packages and pixels that are served through our gateway. If users have DNT turned on in their browser settings, we will not track file downloads or pixel views.</p>"},{"location":"gateway/#availability","title":"Availability","text":"<p>Scarf Gateway is a free hosted service that is publicly provided as-is and as-available.</p> <p>Scarf Gateway is deployed on AWS in multiple regions around the globe; it is fault tolerant even to entire regions going offline, and can automatically scale our backend capacity to meet whatever user traffic demands of us.</p> <p>We aim for a monthly service uptime percentage of 99.9%. If you need uptime and/or support SLAs to guarantee that uptime for your company, please contact sales@scarf.sh</p> <p>To see Scarf's historical uptime and system status, you can view the status page here.</p>"},{"location":"gateway/#badges","title":"Badges","text":"<p>All packages on Scarf Gateway offer dynamic Scarf-powered README badges automatically. Head to your package page, and the badges will be shown in the details section near the top. Copy the URL, paste it into your project\u2019s README based on whatever doc format you are using and you\u2019re all set.</p> <p></p> <p>What is the difference between the downloads badge and the company badge?</p> <p>The commercial usage badge shows how many distinct companies have been identified to be fetching your Scarf Gateway package in the previous month. The downloads badge reports the total number of downloads across all users.</p> <p>What is the purpose of this badge?</p> <p>README badges let you show off your project by sharing high-level real-time data about your download traffic and commercial adoption, so readers can quickly assess some basic details about your project. Scarf-powered README badges are an easy way to share your project\u2019s usage data publicly, regardless of where on the internet your docs are being rendered. Telling prospective new users how many companies use your project is a great way to show that your project is reliable and worth adopting.</p> <p>What is the URL format of the badges</p> <p>The badges can be used in the following formats:</p> <ul> <li> <p>Company Badge</p> <ul> <li>https://scarf.sh/package/company-badge/{package-id}</li> <li>https://scarf.sh/company-badge/{username}/{package-name}?package-type={package-type}</li> </ul> </li> <li> <p>Downloads Badge</p> <ul> <li>https://scarf.sh/package/installs-badge/{package-id}</li> <li>https://scarf.sh/installs-badge/{username}/{package-name}?package-type={package-type}</li> </ul> </li> </ul> <p>You can also pass some additional settings to your badges via query strings: <code>color</code>, <code>label-color</code>, <code>logo</code>, <code>logo-color</code> and <code>style</code>. For example, <code>https://scarf.sh/package/installs-badge/{package-id}?color=red&amp;style=flat</code>. See https://shields.io/#colors to know more about the supported values for each setting.</p>"},{"location":"gateway/#caveats-and-limitations","title":"Caveats and Limitations","text":"<p>A given subdomain can only point to a single container registry at a time.</p> <p>If you have Docker container images on multiple distinct registries, you'll currently need to use multiple distinct subdomains (one per hosting provider). This limitation is due to the current implementation of the Docker registry authorization. To begin pulling a container, an authentication request is sent, which must be passed to the hosting provider you configure Scarf Gateway to use. Unfortunately, the initial authorization request doesn't include any information about what image it's trying to pull all Scarf Gateway has to go on is the hostname used to begin to pull the Docker container image. Subsequent Docker API requests do the actual \"pulling\" of an image. The core of the problem is that, if you attempt to authorize with one registry and pull an image from another, it will fail with an authorization error.</p> <p>The path used in your container's new pull command must match the path on the backend container registry</p> <p>If your container is on Docker Hub as <code>acme/rocket-skates</code>, your install command must be: <code>docker pull ~&lt;your-domain.com&gt;/acme/rocket-skates</code>. The image name path (acme/rocket-status) is not something that can be changed at this time. This is due to the Docker client's OAuth implementation (authorization includes the image name path of the being requested.) If Scarf Gateway redirects to a different path, the authorization becomes invalid and the Docker pull will fail.</p>"},{"location":"gateway/#automatic-package-creation-for-containers","title":"Automatic Package Creation for Containers","text":"<p>Rather than creating packages entries for each container in your namespace, you can specify rules to automatically forward all matching traffic and create package entries automatically. By using a template, e.g. <code>repository/*</code>, every time an image matching that template is first downloaded, Scarf will automatically create a page for that package (e.g. repository/test01, repository/new-item).</p>"},{"location":"gateway/#creating-collections","title":"Creating Collections","text":"<p>To acces Collections, in the top menu click <code>Tools</code> &gt; <code>Collections</code>.</p> <p></p> <p>You will now be presented with the <code>Collections</code> page that give you the options to edit, delete, and create new collections.</p> <p></p> <p>To create a new collection, please first insert the template that will be used. It can be anything of the form: <code>repository/*</code>, <code>repository/{ variable1, variable2 }</code>, etc. Next, insert the backend domain, the domain where your images are hosted (e.g. registry-1.docker.io, ghcr.io, gcr.io). Please keep in mind, each public domain should map to one backend domain. (E.g. If you\u2019re using your Scarf domain for your images hosted on docker, you will not be able to use your Scarf domain for your images hosted on Amazon.) Submit your new rule!</p>"},{"location":"gateway/#faq","title":"FAQ","text":"<p>How do I get started using Scarf Gateway?</p> <p>First, create an account on Scarf, if you haven\u2019t already done so. Once you\u2019ve registered, you\u2019ll be prompted to create a new package. If you\u2019re already using Scarf, you\u2019ll be able to click \u201cNew Package\u201d in the navigation bar.</p> <p>Select \u201cDocker\u201d for your package type and enter in the requested details about your container. Scarf Gateway currently supports Docker containers. Support for more package and artifact types are on the way. Stay tuned.</p> <p>If I use a custom domain to host my container through Scarf, what happens to my existing users? Do they all have to update?</p> <p>Hosting containers on your custom domain via Scarf has no impact on your existing users; your domain adds a new path for users to download your package. You can encourage end-users to switch their pull commands over to your new domain, but they can continue pulling directly from your registry provider with no negative impact.</p> <p>Should you decide to switch registries later on, current users will have to update their pull commands to either your custom domain or to the new registry URL. If they go straight to the registry, they would need to update every time you decide to switch registries. If they use your custom domain, they will never need to update it again.</p> <p>Are you actually hosting my packages?</p> <p>No, your package continues to be hosted on your current hosting provider not on Scarf itself. Scarf Gateway is simply a thin redirect layer in front of your provider. Since Scarf Gateway acts as a stable location on the internet for your packages, you will always have the freedom to host them with any provider you choose.</p> <p>My Docker container image name on my current registry is <code>acme/rocket-skates</code>, can I change that to just <code>rocket-skates</code> when users pull through Scarf?</p> <p>Unfortunately this is not possible unless you can change this name on the registry that hosts your container. Your container name on Scarf must match the container name on the registry that hosts it, because the Docker client uses that name to sign the request and validate the response from the registry. The Docker client will reject the download if the response signature is invalid. See the Caveats section for more information.</p> <p>How are you managing the usage data you get about my project? Are you storing my users\u2019 data?</p> <p>Scarf Gateway does not store any personally identifying information or sensitive data about your users.</p> <p>Scarf looks up IP address metadata, but the raw IP addresses are discarded and never exposed. IP metadata may contain:</p> <ul> <li>Coarse-grained location</li> <li>Device/OS information</li> <li>Company information, cloud providers, etc.</li> </ul> <p>Additionally, Scarf sees metadata about the containers that are being downloaded such as:</p> <ul> <li>Tags/versions (variables)</li> <li>Client runtime and version</li> </ul> <p>What package types are you planning to support next?</p> <p>We\u2019d love your input to help us prioritize support for additional package types. Java, RPM and others are planned. Scarf Gateway will ultimately be generalized to support arbitrary artifact types.</p> <p>How much does it cost to use Scarf Gateway?</p> <p>Scarf Gateway\u2019s current feature set is free and will remain free. We will be adding additional functionality, features, service level agreements, and more, some free and some paid.</p> <p>Is Scarf Gateway self-hosted or managed by Scarf?</p> <p>Scarf Gateway is managed by the Scarf team. We plan an open source release of Scarf Gateway for self-hosting, when it is out of the current open beta period and into general availability.</p> <p>How long will it take for any given container download to show up in my analytics dashboard?</p> <p>Downloads will typically show up in your dashboard in 30 minutes and up to 2-3 hours.</p> <p>Is there an API I can use to pull my stats, manage my packages, etc?</p> <p>Yes! See [our API documentation](https://api-docs.scarf.sh/v2.html** for more information.</p> <p>Is it possible to overwrite the IP address used for a gateway event?</p> <p>Yes, simply set the <code>X-Scarf-IP</code> header to overwrite the IP that will be associated with the request. For bulk event imports, use the <code>$remote_address</code> field in your event JSON payload.</p> <p>I have more questions, where is the best place to ask?</p> <p>Join us in Slack, we're more than happy to help.</p>"},{"location":"gateway/#figures","title":"Figures","text":""},{"location":"gateway/#figure-0-using-scarf-docker-gateway-as-a-maintainer","title":"Figure 0: Using Scarf (Docker) Gateway as a maintainer","text":""},{"location":"gateway/#figure-1-pulling-a-docker-container-image-from-scarf-docker-gateway-as-a-user","title":"Figure 1: Pulling a Docker container image from Scarf (Docker) Gateway as a User","text":""},{"location":"gateway/#figure-2-full-system-diagram-docker","title":"Figure 2: Full System Diagram (Docker)","text":""},{"location":"gateway/#figure-3-using-scarf-file-gateway-as-a-maintainer","title":"Figure 3: Using Scarf (File) Gateway as a maintainer","text":""},{"location":"gateway/#figure-4-downloading-a-file-from-scarf-file-gateway-as-a-user","title":"Figure 4: Downloading a File from Scarf (File) Gateway as a User","text":""},{"location":"gateway/#figure-5-full-system-diagram-file","title":"Figure 5: Full System Diagram (File)","text":""},{"location":"gcp/","title":"Working with Scarf on Google Cloud","text":"<p>Scarf offers a variety of ways to integrate into your workflows on Google Cloud, from monitoring your artifacts that are GCP-hosted, eg Google Artifact Registry, to getting data and insights into your GCP-hosted storage systems.</p>"},{"location":"gcp/#enhanced-download-tracking-from-google-artifact-registry","title":"Enhanced download tracking from Google Artifact Registry","text":""},{"location":"gcp/#configure-your-collection","title":"Configure your collection","text":"<p>Scarf offers a way to track container downloads across your entire project and repository by configuring a Collection</p> <p>To acces Collections, in the top menu click <code>Tools</code> &gt; <code>Collections</code>.</p> <p></p> <p>You will now be presented with the <code>Collections</code> page that give you the options to edit, delete, and create new collections.</p> <p></p> <p>To create a new collection:</p> <ol> <li>Insert the <code>Path</code> that will be matched against on your domain. Artifact Registry images take the form <code>{project_id}/{repository}/{image}</code>; well-formed Scarf path patterns will take the form of <code>your-project-id/*/*</code> to match against any repository and image in your project_id.</li> <li>Next, insert a fully concrete <code>Backend Domain</code> of the form: <code>{your-location}-docker.pkg.dev</code>, eg <code>us-west1-docker.pkg.dev</code>. This is where Scarf will redirect your traffic that match the <code>Public Domain</code> and <code>Path</code> template you set.</li> <li>Finally, enter the <code>Public Domain</code> you'd like to use. This can be <code>your-organization.docker.scarf.sh</code> or a custom domain of your choice.</li> </ol> <p>As soon as your images are pulled, Scarf will create your package entries automatically. No additional configuration is needed as you push new containers to Artifact Registry.</p> <p>Learn more about collections here.</p>"},{"location":"gcp/#enhanced-download-tracking-from-google-cloud-storage","title":"Enhanced download tracking from Google Cloud Storage","text":"<p>Create a File Package as described with a few GCP specific attributes.</p> <p>For your <code>File location</code> template, enter <code>https://storage.googleapis.com/{bucket_name}/{object_name}</code>.</p> <p>In your <code>Desired path format</code>, you can specify arbitrary formats, as long as any variables in your <code>File location</code> are also specified. For instance something as simple as:</p> <pre><code>/{bucket_name}/{object}\n</code></pre> <p>This can be customized further as needed, or made more concrete for specific buckets or objects. Read more about File Packages for more information.</p>"},{"location":"getting-started-checklist/","title":"Getting Started Checklist","text":"<ol> <li>Create a Scarf account.</li> <li>Set up a Scarf Organization for your project. You will see each Organization you belong by clicking on \u201cOrganizations\u201d in the navbar or under the drop-down menu at the top right.</li> <li>Track artifact downloads with Scarf Gateway, which sits in front of artifact downloads through a custom domain and redirect to track information about Docker containers, files, npm packages, or Python packages that are downloaded.<ol> <li>Set up a new package URL via the Scarf Gateway within your Scarf Dashboard, and configure your package to redirect to wherever your artifacts are currently hosted.</li> <li>Update installation and setup documentation to direct users to use the gateway.</li> <li>Update installation scripts, helm charts, docker compose files, etc to fetch resources through your Scarf Gateway endpoint.</li> <li>Check that the Package is set up properly by the artifact and seeing that it shows up in your Scarf Dashboard.</li> </ol> </li> <li>Documentation and/or website tracking with a Scarf Pixel:<ol> <li>Create a Scarf Pixel</li> <li>Embed the Pixel in the HTML for the pages you want analytics for (whether on your site or on third-party sites).</li> <li>Check that the Pixel is loading by opening the page you\u2019ve embedded it on and seeing that it shows up in your Scarf Dashboard.</li> </ol> </li> <li>Set up telemetry<ol> <li>Use Scarf SDKs like scarf-py, scarf-go, etc to send telemetry calls to Scarf from your code.</li> <li>Use dependencies like scarf-js to automatically add <code>postInstall</code> telemetry to your npm packages.</li> </ol> </li> <li>After testing the various methods you can use to measure downloads, views, and access with Scarf, build a plan for what you want to track and what sort of data you want to see.<ol> <li>Roll out Scarf tracking to all your projects/sites.</li> </ol> </li> </ol>"},{"location":"hubspot/","title":"Hubspot","text":""},{"location":"hubspot/#hubspot-requirements","title":"HubSpot Requirements","text":"<ul> <li>A Scarf account with an Organization set-up and an active Premium Subscription.</li> <li>A HubSpot instance.</li> </ul>"},{"location":"hubspot/#required-permissions","title":"Required Permissions","text":"<ul> <li>Scarf:<ul> <li>Owner or Admin Permissions</li> </ul> </li> <li>HubSpot:<ul> <li>Account with Super Admin permissions</li> </ul> </li> </ul>"},{"location":"hubspot/#implementation-process","title":"Implementation Process","text":""},{"location":"hubspot/#creation-of-a-scarf-application-in-hubspot","title":"Creation of a Scarf Application in HubSpot","text":"<p>The Scarf integration to HubSpot is a Private App.</p> <ol> <li> <p>Login to HubSpot as a user with App Marketplace and Developer tools permissions</p> </li> <li> <p>Navigate to your <code>Settings</code> by clicking the gear icon on the top right.</p> </li> <li> <p>In the left sidebar, click on <code>Integrations</code> -&gt; then click <code>Private apps</code> -&gt; and select <code>Create a private app</code>.</p> </li> </ol> <p> </p> <ol> <li>Provide a name for your application such as \u201cScarf Connection\u201d, optionally enter a Description such as \u201cScarf Connection to import usage analytics\u201d.</li> </ol> <p> </p> <ol> <li>Navigate to the <code>Scopes</code> tab and configure the desired scopes for the integration.</li> </ol> <p> </p> Scope Area Scope Name Required Explanation CRM <code>crm.objects.companies.read</code> Yes Required for Scarf to read company objects CRM <code>crm.objects.companies.write</code> No Required for Scarf to Create or Update Companies CRM <code>crm.objects.contacts.read</code> Yes Required for Scarf to read company objects CRM <code>crm.objects.owners.read</code> Yes Required for Scarf to read company objects Other <code>sales-email-read</code> Yes Required for Scarf to read company objects <ol> <li> <p>Click the <code>Create App</code> button in the top right.</p> </li> <li> <p>Copy the API token presented and make note of it for the Connection and Authentication step below.</p> </li> </ol> <p> </p>"},{"location":"hubspot/#connection-and-authentication","title":"Connection and Authentication","text":"<ol> <li> <p>Login to Scarf as a user with Owner or Admin permissions.</p> </li> <li> <p>Navigate to <code>Organization Settings</code> -&gt; <code>Integrations</code>.</p> </li> </ol> <p> </p> <ol> <li>Select <code>Connect CRM Instance</code>, confirm you want to sync companies and click <code>Finish linking CRM</code>.</li> </ol> <p> </p> <ol> <li>Click <code>HubSpot</code> from the <code>Select integration</code> menu.</li> </ol> <p> </p> <ol> <li>Review the presented data permissions, and click <code>Next</code>.</li> </ol> <p> </p> <ol> <li>When prompted enter your HubSpot Company ID, and click <code>Next</code>.</li> </ol> <p> </p> <ol> <li>You will now be prompted to enter the API Key generated in the Scarf Application stage, if required this can be retrieved from the <code>Private App Settings</code> page.</li> </ol> <p> </p> <ol> <li>Click <code>Next</code> and Scarf is now connected to your HubSpot instance.</li> </ol>"},{"location":"hubspot/#scarf-field-configuration","title":"Scarf Field Configuration","text":"<p>The HubSpot connection allows you to pair Scarf Surfaced Companies with Account records in HubSpot, and optionally to create new Account records when Company Matches are surfaced. In addition to account records, Scarf will attempt to publish metrics to the HubSpot Account record if a matching Field is found on the account. If no matching Fields are found on an Account Object, Scarf will not update the record. The Fields Scarf will attempt to publish are enumerated here:</p> Property Label (suggested) Internal Name (required) Object Type Description Scarf Company <code>scarf_company_name</code> string Company Name as determined by Scarf Enrichment Scarf Domain <code>scarf_company_domain</code> string Primary Internet Domain of the Company Scarf First Seen <code>scarf_first_seen</code> date Date of First Event Scarf observed attributed to this Company Scarf Last Seen <code>scarf_last_seen</code> date Date of most recent Event Scarf observed attributed to this Company Scarf Funnel Stage <code>scarf_funnel_stage</code> string Current Adoption Funnel Stage of the Company Scarf Total Events <code>scarf_total_events_last_30_days</code> number Total observed events in the last 30 days Scarf Total Uniques <code>scarf_total_unique_sources_last_30_days</code> number Unique observed Event Sources (endpoints) in the last 30 days Scarf Events MoM <code>scarf_total_events_mom</code> number Change in Total Events over the previous Month Scarf Events WoW <code>scarf_total_events_wow</code> number Change in Total Events over the previous Week Scarf Sources MoM <code>scarf_total_unique_sources_mom</code> number Change in Unique Sources over the previous Month Scarf Sources WoW <code>scarf_total_unique_sources_wow</code> number Change in Unique Sources over the Previous Week"},{"location":"hubspot/#create-scarf-data-fields-in-hubspot","title":"Create Scarf data fields in HubSpot","text":"<p>If present and if Write scope has been granted, Scarf will update HubSpot Company records with Scarf custom properties.</p> <p>While logged in as a user with Edit property settings permissions:</p> <ol> <li> <p>In your HubSpot account, click the <code>Settings</code> icon in the top navigation bar.</p> </li> <li> <p>In the left sidebar menu, navigate to <code>Properties</code>.</p> </li> <li> <p>Click the <code>Select an object</code> dropdown menu, then select <code>Company properties</code>.</p> </li> </ol> <p> </p> <ol> <li>Create a <code>Property Label</code> for each of the fields described above, as desired.</li> </ol> <p> </p>"},{"location":"hubspot/#synchronization-frequency","title":"Synchronization Frequency","text":"<p>Scarf currently synchronizes with your CRM nightly. The duration of the sync is dependent on the volume of records paired. Manual Company matches are queued for the next nightly sync.</p>"},{"location":"hubspot/#configuring-the-connection","title":"Configuring the Connection","text":"<p>Once the CRM connection has been initialized, the Integrations menu will add three configuration options:</p> <p>Enable Scarf to connect Insights to this CRM Toggling this to off will temporarily disable the CRM integration. While off no reading or writing will be attempted.</p> <p>Auto-match to known Accounts from Scarf With the integration enabled, you have the option to set Scarf to to use text pattern matching to pair existing CRM Accounts with surfaced Scarf Companies. If the setting is off then all mapping will be performed manually.</p> <p>Automatically create new Accounts in your CRM With the integration enabled, you also have the option to set Scarf to attempt to create a new Account record in your CRM when the sync process encounters a Company without a match in the CRM. This will include historical matches as well as any newly surfaced companies.</p> <p> </p> <p>NOTE: By default, all options will be turned on except for Auto-Sync, which will be off. Since Auto-Sync automatically creates records, it is disabled by default to prevent unintended data updates. Users can enable it manually once they have reviewed their setup.</p>"},{"location":"mtc/","title":"Monthly Tracked Companies (MTCs)","text":"<p>Scarf identifies which companies are viewing your documents, downloading your packages, or executing your software, and tracks their activity across the organization. These are referred to as Monthly Tracked Companies (MTCs). Scarf enriches IP addresses with several metadata sources to provide the most accurate data possible.</p>"},{"location":"mtc/#consumption-of-mtcs","title":"Consumption of MTCs","text":"<p>MTCs are consumed any time a company is seen for the first time in a given month. For example, if you have purchased 100 MTCs, you will see the first 100 companies that interact with your open source and no further companies will be surfaced for the remainder of the month. MTCs reset on a monthly basis at the start of the calendar month.</p> <p>NOTE: There is no way to predict which companies will surface, or how quickly. Companies are surfaced in the order they are seen, until your MTC limit is reached.</p> <p>Scarf will always show you the total number of companies interacting with your project at the bottom of the Company Insights page. You can update your plan's MTC quota in your Organization settings. You can also track your MTC usage by day in your Organization settings.</p>"},{"location":"mtc/#match-feedback","title":"Match Feedback","text":"<p>Match Feedback allows you to confirm, deny, or fix your company matches. Companies marked with negative match feedback will not consume MTCs the following month.</p> <p></p>"},{"location":"mtc/#faq","title":"FAQ","text":"<p>How do I know how much of my MTC quota I\u2019ve used?</p> <p>You will see a count of the currently used MTCs at the bottom of the Company Insights page.</p> <p></p> <p>It is also available on the Organization settings page.</p> <p> </p> <p>What if I want to see more companies?</p> <p>You can always increase the number of MTCs on your account to see more. If you are using the Scarf Starter package you can add up to 500 MTCs by going into your account Settings &gt; Billing/Subscription and adding more. If you are using any other Scarf package, contact sales or your customer success manager for more information.</p> <p></p> <p>Why do I occasionally see fewer companies on my Scarf home page than I am allocated?</p> <p>Scarf\u2019s home page will always show you metrics from the last 30 days. Because the MTC quota resets at the beginning of each month, there is sometimes a perceived \u201cgap\u201d in the number of companies shown on the home page in the \u201cEvents by Company\u201d chart. While the home page is designed to provide an \u201cat-a-glance\u201d overview of overall activity, it may be easier to get the full picture of the companies present within a given period (within the MTC quota** by visiting the Company Insights page.</p> <p>When I look at the results on the Company Insights page for last month (using the custom time range), I see that 3,045 of my 5,000 allocated companies are being shown. Why do I not see all 5,000 of my MTCs?</p> <p>Scarf displays the companies present at that point in time that are also present in the current month\u2019s quota. In other words, 3,045 of the companies present last month are also in this month\u2019s data. The remaining companies we matched last month are inactive in the current month\u2019s data. As companies interact with your project in that given month, they will be added to the count until you reach your full MTC quota.</p>"},{"location":"oql/","title":"Open Source Qualified Leads ( OQLs )","text":""},{"location":"oql/#definition","title":"Definition","text":""},{"location":"oql/#what-is-an-open-source-qualified-lead-oql","title":"What is an Open Source Qualified Lead (OQL)?","text":"<p>An Open Source Qualified Lead (OQL) is an individual or organization that has shown a measurable level of engagement in open-source communities or projects, indicating a likely interest in a particular product or service that adds value to their open-source activities. This data-driven insight is crucial for identifying growth strategies, developer relations initiatives, and targeted sales or marketing campaigns.</p>"},{"location":"oql/#relevant-content-for-further-understanding","title":"Relevant Content for Further Understanding","text":"<p>By incorporating these broader concepts into the definition of an OQL, it becomes easier for everyone in an organization to understand and utilize the term effectively.</p>"},{"location":"oql/#lead-generation","title":"Lead Generation","text":"<p>In marketing, lead generation stimulates interest in a product or service to develop a sales pipeline. In the context of open source, this could involve tracking contributions, forum activity, or other community engagement metrics.</p>"},{"location":"oql/#lead-scoring","title":"Lead Scoring","text":"<p>This involves assigning a numerical value to each lead based on various factors like their level of interest, fit with the target market, and likelihood of becoming a customer. This could be based on the number of pull requests, issues raised, or other community contributions in the open-source context.</p>"},{"location":"oql/#lead-qualification","title":"Lead Qualification","text":"<p>This is the process of filtering leads based on specific criteria such as demographic information and behavioral actions. For OQL, this could involve analyzing the types of open-source projects they are involved in, their level of activity, and their expressed needs or pain points.</p>"},{"location":"oql/#why-should-you-track-oqls","title":"Why should you track OQLs?","text":"<ul> <li>Building a baseline and tracking the growth of your user base</li> <li>Planning activities to accelerate the adoption of your open source</li> <li>Enriching and expanding the sales pipeline</li> <li>Determining potential risk from users leaving your ecosystem</li> </ul>"},{"location":"oql/#oql-point-system","title":"OQL Point System","text":""},{"location":"oql/#page-views","title":"Page Views","text":"Event Value Points Limits Example(s) Low 0.25 \u2264 2 points/day\u2264 10 points/month Blog post view Medium 0.5 \u2264 3 points/day\u2264 20 points/month Home page view High 1 \u2264 5 points/day\u2264 30 points/month Pricing page view"},{"location":"oql/#downloadpullinstalls","title":"Download/Pull/Installs","text":"Event Value Points Limits Example(s) Low 2 \u2264 6 points/day\u2264 30 points/month Pull <code>latest</code> Medium 5 \u2264 10 points/day\u2264 50 points/month Pull a stable community edition release High 8 \u2264 16 points/day\u2264 42 points/month Pull an enterprise edition"},{"location":"oql/#community-activities","title":"Community activities","text":"<p>Additional recommended activities and events to be tracked based on community activity.</p> Event Value Points Limits Example(s) Low 2 \u2264 2 points/day\u2264 10 points/month Issue comment reaction Medium 5 \u2264 10 points/day\u2264 50 points/month Slack signup, open an issue High 8 \u2264 24 points/day\u2264 48 points/month Pull Request submitted"},{"location":"oql/#oql-status-levels","title":"OQL Status Levels","text":"<ol> <li>Interest - Just viewing docs or site, any downloads immediately trigger Investigation stage.<ol> <li>Less than 10 points.</li> <li>Just pixel activity -  any downloads trigger Investigation stage.</li> </ol> </li> <li>Investigation - Enough activity has occurred for us to suspect the company is actively investigating this open source<ol> <li>Has activily reached more than 10 points but less then 40.</li> <li>They have downloaded at least 1 package and poked around the docs (multiple pixels).</li> <li>Or, we see 2 consecutive weeks of pixel activity.</li> </ol> </li> <li>Experimentation - Enough activity has occurred for us to suspect the company is actively using this open source software for one or more production systems<ol> <li>Has activity that has reached 40 to 70 points.</li> <li>Multiple downloads and pixels over the course of 30 days.</li> <li>Or, single download and multiple pixels over the course of 60 days.</li> <li>and Active in the last 30 days.</li> </ol> </li> <li>Ongoing Usage - Enough activity has been detected for us to suggest that this user may be ready to be a customer and should feed into the sales/marketing pipeline if available. If this is not a commercial open-source project, OQL3 would be a good indicator that this company may be a good sponsorship target or may prove to be a valuable advocate in the in the community.<ol> <li>Has activity that has reached 70+ points.</li> <li>Continued downloads or pixel fetches, over 90 days of history, active in the last 90 days.</li> </ol> </li> <li>Inactive - Former OQL that qualified, but overtime has gone cold or is unverified.<ol> <li>We saw activity at some point, but we haven\u2019t seen anything in 60 days.</li> <li>Previously reach an Investigation, Experimentation, or Ongoing Usage status, but no longer meets this requirement.</li> </ol> </li> </ol>"},{"location":"oql/#practical-example","title":"Practical Example:","text":"<p>There are different ways to build an OQL depending on the project, outcome, and needs.  But for our example, let\u2019s say that we determine an OQL should perform the following:</p> <ul> <li>Download the software packages more than once over the course of more than 3 days<ul> <li>Indicating more than merely a passive one-time download.</li> </ul> </li> <li>Viewing the docs over the course of multiple days<ul> <li>The more unique people from the same company the better.</li> </ul> </li> <li>Active participation in 1 or more community channels (Github, Slack, forums, etc)<ul> <li>This shows more investment in understanding and using the software\u2026 but often only 1 out of 10 users will show up here.</li> </ul> </li> <li>Activity (either downloads, documentation views, Slack messages, etc) within the last 31 days</li> </ul> <p>Assuming you have seen a single company or person do the above activities, you have high confidence that this company is at least investigating your software.</p> <p>We could enrich this data even further by looking at things like:</p> <ul> <li>Activities over a 3 month or 6 month period<ul> <li>This would indicate ongoing usage.</li> </ul> </li> <li>Ongoing or repeated page views or searches for a specific feature or solution<ul> <li>This would help identify a potential desire to use or better understand a specific feature.  This could also represent a place where they are stuck.</li> </ul> </li> <li>Page views to pricing or signup pages<ul> <li>This, combined with ongoing activities over a sustained period, would indicate a strong potential interest for a commercial relationship.</li> </ul> </li> </ul> <p>If you are tracking a company's OQL status over time, this can help you estimate churn and understand potential changes in the sentiment of your project. Consider if you have a user who reached an Ongoing Usage and purchased something from your company. For 2 years this company has maintained this status. Then, for the last 2 months, they have not reached the same status. Why has their download pattern changed? Why did they stop participating in your community? Are they going to move to something else? Knowing this enables you to get ahead of any potential issue.</p>"},{"location":"oql/#sample-setup","title":"Sample Setup","text":"<p>Below we will outline a basic setup for scoring and qualifying OQL\u2019s.   We recommend starting with a simple point system to qualify leads over a 30/60/90 day period. In a point system each activity is worth a certain amount of points, once you reach a certain number of points and/or logic gates that moves a lead to the appropriate lead level. We also recommend that you track OQL\u2019s at the company level. Many of the activities will occur from servers and won\u2019t be associated with end user accounts.</p>"},{"location":"oql/#faq","title":"FAQ","text":""},{"location":"oql/#how-is-an-oql-different-from-an-mql","title":"How is an OQL different from an MQL?","text":"<p>A marketing qualified lead (MQL) is similar to an OQL but contains different activities and is focused on a different part of a user's journey.  While an OQL is tracking user and community activities, the MQL will track interactions with marketing activities.  We recommend overlapping webpage visits for both MQL\u2019s and OQL\u2019s, but other than that the OQL is focused on open source adoption, and then the MQL is focused on closing new commercial customers.</p> <p>An OQL could become an MQL which could eventually become an sales qualified lead (SQL).</p>"},{"location":"organizations/","title":"Organizations","text":""},{"location":"organizations/#creating-an-organization","title":"Creating an organization","text":"<p>If you\u2019re part of a company, open-source team, or have multiple stakeholders managing packages, converting to a Scarf Organization simplifies management and scales better than an individual account. </p> <p>To create an organization, in the header menu click on the <code>Organization</code> button,</p> <p></p> <p>alternatively, you can access it via the plus icon and selecting <code>New Organization</code></p> <p></p> <p>If you haven't already setup an organization you will be presented with the following screen:</p> <p></p> <p>As you can see you are presented with two options:</p> <ol> <li> <p>Create Organization: This is if you are happy to keep your user and create a free standing organization.</p> </li> <li> <p>Convert Account to organization: If it happens that you've added lots of new packages and found that you'd like to put these under an organization umbrella this is the perfect way to achieve that.</p> </li> </ol>"},{"location":"organizations/#converting-your-current-account-to-an-organization","title":"Converting your current account to an organization","text":"<p>If your current username is what you would like your organization to be called, you can convert your account into an organization. To do this, please follow the steps below:</p> <p>From the splash screen shown above click on <code>Convert Account to organization</code>. You will be presented with the following:</p> <p> Click on <code>Get Started</code> and you will see:</p> <p></p> <p>You now need to select a new username as your current username will be converted into an organization and the new username will be the owner of this newly created organization. Fill in the other inputs as required.</p> <p>Lastly before clicking <code>Save</code> be mindful that all of your account\u2019s packages will be transferred to the organization.</p> <p>That's it you have now converted your account into an organization, the next screen you will see is the organization screen.</p> <p></p> <p>Now as previously prompted log out and back into your account. You will be presented with the following home page just like when you first open your account. Do not be alarmed, not all is lost it's just that all your data/packages have been transferred to your new organization. </p> <p>To access these you now have access to new menu items in the top right header menu, it will look as follows:</p> <p></p> <p>Now select the organization and you will see all of your previously created packages and data.</p> <p>A little helpful feature is when looking at the top right header menu you will now see two circles. The larger being what organization you are accessing and the smaller one being the user you are doing it with.</p> <p></p> <p>If you ever want to go back to your user then simply select it in the dropdown menu.</p>"},{"location":"organizations/#directly-creating-an-organization","title":"Directly creating an organization","text":"<p>In a very similar fashion to the converting you current account to an organization, simply select the option from the plus icon dropdown menu. </p> <p>The next screen will prompt you to add your new organization name and other details, click <code>Save</code> </p> <p>Et voil\u00e0! You now have new organization</p> <p></p>"},{"location":"organizations/#managing-your-organization","title":"Managing your Organization","text":""},{"location":"organizations/#filter-settings","title":"Filter Settings","text":"<p>You can manage Filter settings for your Organization by clicking into Filter Settings on your organization overview. </p>"},{"location":"organizations/#data-providers","title":"Data providers","text":"<p>Scarf partners with 3rd party data providers in order to surface IP-address metadata like the location or company behind any event in your account.</p> <p>Scarf's enhanced company matching capabilities feature a Clearbit integration to help us offer best-in-class data quality. Enabling Clearbit for your organization is free! Additional terms apply.</p> <p>To enable this Clearbit for your organization, navigate to your organization overview page, and find the section <code>Toggle Data Providers</code>. It is not enabled by default.</p> <p></p> <p>Complementary Clearbit access is already included in your Scarf plan</p> Scarf Tier Included Clearbit calls per month Basic 10,000 calls/month included Premium 25,000 calls/month included, with pay-per-usage upgrades <p>For more information about enhanced company insights, contact our sales team.</p>"},{"location":"package-analytics/","title":"Scarf SDKs for library and package authors","text":"<p>Scarf's programming language SDKs provide observability into the usage of your libraries and language-specific packages. By adding a dependency to scarf-js or another Scarf language-level library, you can gain better data insights into how your package is used, and by which companies.</p>"},{"location":"package-analytics/#javascript","title":"JavaScript","text":""},{"location":"package-analytics/#features","title":"Features","text":"<ul> <li>Collects basic installation statistics on <code>npm install</code>.</li> <li>No dependencies</li> <li>Fully transparent to the user. Scarf will log its behavior to the console during installation. It will never silently report analytics for someone that hasn't explictly given permission to do so.</li> <li>Never interrupts your package installation. Reporting is done on a best effort basis.</li> </ul> <p>You can find scarf-js on GitHub or on npm directly.</p>"},{"location":"package-analytics/#installation","title":"Installation","text":"<p>You'll first need to create a package entry on Scarf. Be sure to select \"External library\", and set the package type to \"npm\".</p> <p>Once created, add a dependency on this library to your own:</p> <pre><code>npm i --save @scarf/scarf\n</code></pre> <p>Once your library is published to npm with this change, Scarf will automatically collect stats on install, no additional code is required!</p> <p>Head to your package's dashboard on Scarf to see your reports when available.</p>"},{"location":"package-analytics/#how-does-it-work","title":"How does it work?","text":"<p><code>scarf-js</code> registers a <code>postInstall</code> hook that sends telemetry information. This library has no runtime footprint, it only runs at installation time, when a developer runs <code>npm install</code> Continue reading below here</p>"},{"location":"package-analytics/#configuration","title":"Configuration","text":"<p>Users of your package will be opted in by default and can opt out by setting the <code>SCARF_ANALYTICS=false</code> environment variable. If you'd prefer to set Scarf analytics  such that users will be opted out by default instead, you can set this by adding an entry  to your <code>package.json</code></p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"defaultOptIn\": false\n  }\n  // ...\n}\n</code></pre> <p>Scarf will now be opt-out by default, and users can set <code>SCARF_ANALYTICS=true</code> to opt in.</p> <p>Regardless of the default state, Scarf will log what it is doing to users who haven't explictly opted in or out.</p> <p>By default, scarf-js will only trigger analytics when your package is installed as a dependency of another package, or is being installed globally. This ensures that scarf-js analytics will not be triggered on <code>npm install</code> being run within your project. To change this, you can add:</p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"allowTopLevel\": true\n  }\n  // ...\n}\n</code></pre>"},{"location":"package-analytics/#faq","title":"FAQ","text":""},{"location":"package-analytics/#what-information-does-scarf-js-provide-me-as-a-package-author","title":"What information does scarf-js provide me as a package author?","text":"<ul> <li>Understanding your user-base</li> <li>Which companies and organizations are using your package?</li> <li>Is your project growing or shrinking? Where? On which platforms?</li> <li>Which versions of your package are being used?</li> </ul>"},{"location":"package-analytics/#what-information-does-scarf-js-send","title":"What information does scarf-js send?","text":"<p>See more here.</p>"},{"location":"package-analytics/#as-a-user-of-a-package-using-scarf-js-how-can-i-opt-out-of-analytics","title":"As a user of a package using scarf-js, how can I opt out of analytics?","text":"<p>Scarf's analytics help support developers of the open source packages you are using, and provide data insights to help improve their software, so your opt-in is appreciated. However, if you'd like to opt out, you can add your preference to your project's <code>package.json</code>:</p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"enabled\": false\n  }\n  // ...\n}\n</code></pre> <p>Alternatively, you can set this variable in your environment:</p> <pre><code>export SCARF_ANALYTICS=false\n</code></pre> <p>Either route will disable Scarf for all packages.</p>"},{"location":"package-analytics/#how-can-i-inspect-the-json-payload-that-scarf-js-sends","title":"How can I inspect the JSON payload that scarf-js sends?","text":"<p>scarf-js will run in verbose mode depending on the <code>SCARF_VERBOSE</code> environment variable:</p> <pre><code>export SCARF_VERBOSE=true\n</code></pre> <p>It will print out the JSON payload, as well as any debugging information.</p>"},{"location":"package-analytics/#i-distribute-a-package-on-npm-and-scarf-js-is-in-our-dependency-tree-can-i-disable-the-analytics-for-my-downstream-dependents","title":"I distribute a package on npm, and scarf-js is in our dependency tree. Can I disable the analytics for my downstream dependents?","text":"<p>Yes. By opting out of analytics via <code>package.json</code>, any package upstream will have analytics disabled.</p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"enabled\": false\n  }\n  // ...\n}\n</code></pre> <p>Installers of your packages will have scarf-js disabled for all dependencies upstream from yours.</p>"},{"location":"package-analytics/#i-have-more-questions-where-is-the-best-place-to-ask","title":"I have more questions, where is the best place to ask","text":"<p>Join us in Slack, we're more than happy to help.</p>"},{"location":"package-analytics/#developing","title":"Developing","text":"<p>Setting the environment variable <code>SCARF_LOCAL_PORT=8080</code> will configure Scarf to use http://localhost:8080 as the analytics endpoint host.</p>"},{"location":"package-analytics/#data-collection-and-privacy","title":"Data collection and privacy","text":"<p>Scarf does not store any personally identifying information from SDK telemetry data. Scarf only collects information that is helpful for:</p> <ul> <li>Package maintenance</li> <li>Identifying which companies are using a particular package, in order to enable support agreements between developers and commercial entities.</li> </ul> <p>Specifically, scarf-js sends:</p> <ul> <li>The operating system you are using.</li> <li>Your IP address will be used to look up any available company information. Scarf does not store the actual IP address</li> <li>Limited dependency tree information. Scarf sends the name and version of the package(s) that directly depend on scarf-js. Additionally, scarf-js will send SHA256-hashed name and version for the following packages in the dependency tree:</li> <li>Packages that depend on a package that depends on scarf-js.</li> <li>The root package of the dependency tree. This allows Scarf to provide maintainers with information about which public packages are using theirs, without exposing identifying details of non-public packages.</li> </ul>"},{"location":"package-analytics/#more-languages-coming-soon","title":"More languages coming soon","text":"<p>We're working to build out sibling libraries for various languages beyond JavaScript. If you're interested in using Scarf in a language we haven't released yet, let us know!</p>"},{"location":"packages/","title":"Setting up Scarf Packages","text":""},{"location":"packages/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>You will need to sign up for a Scarf account.</p> <p>Note: You can sign up with a valid email address or your GitHub account.</p> </li> <li> <p>To track a container, it must be published to a public registry; eg Docker Hub, GitHub Container Registry.</p> <p>Note: This guide will use the <code>hello-world</code> docker image.</p> </li> </ul>"},{"location":"packages/#docker-packages","title":"Docker Packages","text":""},{"location":"packages/#creating-a-docker-package","title":"Creating a Docker Package","text":"<p>Using Scarf, users can pull your Docker container images via Scarf Gateway using your custom domain.</p> <ol> <li>Once signed in to Scarf, navigate to the home page.</li> <li>Click plus icon in the top navigation, then select <code>New Package</code>.     </li> <li>In the first drop-down click on the package type you would like to create. For this section you will click <code>Docker</code>.     </li> <li> <p>Enter the current pull command for your Docker container.</p> <pre><code># `hello-world` package\n\ndocker pull hello-world\n</code></pre> <p></p> </li> <li> <p>Optional: You can add a custom domain or use the domain provided by Scarf Gateway.</p> </li> <li>Click the <code>Submit</code> button to be redirected to a success screen with some additional information as to what you can do next.</li> <li> <p>Click on on <code>Go to your package</code> to view your package details view.</p> <p></p> </li> </ol> <p>Now you\u2019re all set to start tracking your Docker images with Scarf. Any time your image is downloaded, Scarf will report the following information:</p> <ul> <li>System and OS statistics of your users</li> <li>Company information of your users</li> <li>Downloads by versions/tags</li> </ul> <p>In the next section, you will create a tracking pixel that can be added to your project\u2019s documentation or any other web properties associated with your project.</p>"},{"location":"packages/#downloading-docker-packages","title":"Downloading Docker Packages","text":"<p>In this section you will download your package with the pull command found in your package dashboard to start fetching data.</p> <ol> <li> <p>Navigate to your package details view.</p> <p></p> </li> <li> <p>Copy the Pull command.</p> </li> <li> <p>Navigate to a terminal on your computer and run the Pull command.</p> <p></p> <p>Note: Make sure the docker daemon is running on your computer. 6. Back to the package details view and click on <code>View Analytics</code>. You should now see the Package Insights starting to populate with data. It will usually take 30 minutes and up to 2-3 hours before you see data pulled in. Every time a user pulls your Docker container images from Scarf Gateway the data in your Package Insights will be updated. </p> </li> </ol>"},{"location":"packages/#file-packages","title":"File Packages","text":"<p>File Packages on Scarf are a flexible and low-level package type that can track visits and downloads on arbitrary URLs. File packages were originally created to track published tar balls, but it has since expanded to many other use cases. You can think of File Packages as a powerful and fully customizable link shortener. Common use cases include:</p> <ul> <li>Tracking downloads of GitHub release artifacts</li> <li>Tracking downloads of every artifact on your company/project \"downloads\" page</li> <li>Tracking downloads of Homebrew packages from a tap/formula that you control</li> <li>Sending custom telemetry or other events from your application</li> <li>Tracking and attributing visits to marketing and sales content on your site.</li> </ul>"},{"location":"packages/#creating-a-file-package","title":"Creating a File Package","text":"<ol> <li> <p>Log in to your Scarf account.</p> </li> <li> <p>Click the plus icon in the top right navigation, then select New Package. </p> </li> <li> <p>In the first drop-down click on the package type you would like to create. For this section you will click <code>New File</code>. </p> </li> <li> <p>Select a package owner from the dropdown of Organizations you belong to. </p> </li> <li> <p>Give your package a name. </p> </li> </ol>"},{"location":"packages/#adding-an-outgoing-and-incoming-url","title":"Adding an Outgoing and Incoming URL","text":"<p>This section explains what the Outgoing and Incoming URLs are and how to use a URL template to dynamically route new URLs.</p> <p>1.) Add the URL path where your files are currently located. You can add a simple URL or a URL template like in the example. <code>https://www.example.com/mypath/{version}/{platform}.tar.gz</code> This example uses 2 variables <code>{version}</code> and <code>{platform}</code>.</p> <p>Note: The Outgoing URL is the full URL to your asset on your HTTP/S hosting provider. It can be a URL template but if you use variables in your URL they need to also be used in your Incoming Path that define in the next step.</p> <p></p> <p>2.) Choose the domain where your files will be available from. You may choose to use your own domain for serving files. You may also choose to use <code>&lt;username&gt;.gateway.scarf.sh</code> provided by default by Scarf.</p> <p>3.) Add the Incoming URL Path where Scarf will direct requests to fetch a file asset.</p> <p>Note: Any variables used in your Outgoing URL path need to match your Incoming URL.</p> <p></p> <p>4.) Click Submit.</p>"},{"location":"packages/#adding-additional-routes","title":"Adding Additional Routes","text":"<p>This example will show how to add an additional route. For curl-runnings an additional route that redirects to a specific version will be added, in this case, the most recent package release.</p> <p>1.) In the top menu click on Tools then in the drop down menu click on Packages. </p> <p>2.) In the package list dashboard there will be a list of all your packages. These can be filtered by type of packages by selecting the package types you'd like to see. In our example as we just created a file package we're going to want to select File.</p> <p>3.) Navigate to our newly create file package and in the top right of the box click the <code>View Details</code> button. </p> <p>4.) In the popup modal, use the <code>File location</code> input to add a new host URL. You can use a template URL here.</p> <p>Example:</p> <p><code>https://www.example.com/mypath/latest/{platform}.tar.gz</code></p> <p>5.) Next, add the desired path format for your files. Make sure the variables from your Outgoing and Incoming URLs match if you use a template URL.</p> <p>Example:</p> <p><code>/latest/{platform}</code></p> <p></p> <p>6.) Click the <code>Submit</code> button.</p> <p>7.) The modal will close and you will see the additional route you just added.</p> <p></p>"},{"location":"packages/#npm-packages","title":"npm Packages","text":"<p>NPM Packages on Scarf are a convenient way to collect usage and event telemetry from your npm packages by adding a dependency on <code>[scarf-js](https://www.npmjs.com/package/@scarf/scarf)</code>.</p> <ol> <li> <p>Log in to your Scarf account.</p> </li> <li> <p>Click the plus icon in the navigation, then select New Package. </p> </li> <li> <p>In the first drop-down, select <code>npm</code> as the package type.  </p> </li> <li> <p>Select the package owner from the dropdown list of Organizations you belong to. </p> </li> <li> <p>Give your npm package a name. This name should match the name of your package on npm, or the same as the <code>name</code> in your <code>package.json</code>. </p> </li> <li> <p>Click Submit.</p> </li> </ol>"},{"location":"packages/#configuring-telemetry-for-npm-packages","title":"Configuring Telemetry for npm packages","text":"<p>Once an npm entry has been created, you are ready to configure your package by adding scarf as a dependency <pre><code>npm i --save @scarf/scarf\n</code></pre> Once your library is published to npm with this change, Scarf will automatically receive stats on install, no additional code is required! For additional details on configuration of the scarf-js library please refer to the scarf-js NPM entry.</p>"},{"location":"packages/#event-collection-packages","title":"Event Collection Packages","text":"<p>Event Collection Packages on Scarf are another flexible package type purpose built for telemetry data in general. Event data can be sent to a public Scarf Gateway URL of your choice, or by bulk ingesting events through our authenticated API. Event Collection Packages are an alias of File packages and share all the same traits. Common use cases include:</p> <ul> <li>Sending custom telemetry or other events from your application</li> <li>Importing historical event data from an external application into to Scarf</li> </ul>"},{"location":"packages/#creating-an-event-collection-package","title":"Creating an Event Collection Package","text":"<ol> <li> <p>Once signed in to Scarf, navigate to the home page.</p> </li> <li> <p>Click plus icon in the navigation, then select New Package. </p> </li> <li> <p>In the first drop-down click on the package type you would like to create. For this section you will click <code>Event Collection</code>. </p> </li> <li> <p>Select the package owner from the dropdown. </p> </li> <li> <p>Give your package a name. </p> </li> <li> <p>Add the URL path where your events will be collected. This is the user visible endpoint your application will connect to for event submission. This setting while required is not relevant when submitting events via the Event Import API.</p> <p>Note: You can use a URL template, but if you use variables in your URL, they must be present in order for the event to match your route and be collected successfully. Depending on your use case, it may be better to simply pass event data via query parameters and leave your route as something simple and static.</p> </li> <li> <p>Choose the domain where your events will be submitted. You may choose to use your own domain or you may choose to use <code>&lt;username&gt;.gateway.scarf.sh</code> provided by default by Scarf.</p> </li> <li> <p>Click Submit.</p> </li> <li> <p>Once an Event Collection package has been created, you are ready to collect Custom telemetry</p> </li> </ol>"},{"location":"packages/#python-packages","title":"Python Packages","text":"<p>Scarf Gateway configuration for a Python package entry has three main considerations:</p> <ul> <li>pip Command: This is the current pip command used to install your package. For packages on PyPI.org, this will be of the form pip install my-pkg and will include the <code>--extra-index-url https://my-python-project-domain.com</code> if your package is hosted elsewhere. This defines the location where the users will be redirected to when installing your package.</li> <li>Domain: This can be your own domain, or a Scarf-supplied domain, of the form <code>&lt;username&gt;.gateway.scarf.sh</code>. By default, your Scarf domain will be used if this field is left empty.</li> <li>Telemetry: This allows you to gather insights into how your package is used without collecting any personally identifiable information.</li> </ul> <p>Installing Python packages via requirements.txt Add the <code>--extra-index-url</code> option at the top of your requirements.txt:</p> <pre><code>--extra-index-url https://my-python-project-domain.com/simple/ \nmy-pkg==0.0.1\n</code></pre> <p>NOTE: We have noticed indeterminate behavior in some versions of Pip that have resulted in the public registry being used for download regardless of the <code>--extra-index-url</code> addition.</p> <p>If you elect to use your own domain, you'll need to add a CNAME for that domain to <code>gateway.scarf.sh</code>. Additionally we require you to verify your ownership of the domain by setting a TXT with a value that Scarf provides upon package creation. See your DNS provider's instructions for how to add CNAME and TXT records.</p> <p>If you have questions or need help, join our Slack community.</p>"},{"location":"project-status/","title":"Project status","text":"<p>Scarf is still in its early stages and is under heavy development. Feedback of any kind of welcome. Tell us what you think! Reach out to feedback@scarf.sh or open an issue on GitHub for feature requests, bug reports, questions and comments.</p>"},{"location":"quick-start/","title":"Quick Start","text":""},{"location":"quick-start/#introduction","title":"Introduction","text":"<p>Scarf is a platform that helps you track download and usage analytics for your open source project. Scarf can collect analytics for you by:</p> <ul> <li>Tracking the downloads of your software at the point of distribution, regardless of how they are distributed (Docker containers, binaries, Python packages, npm packages, and more).</li> <li>Tracking user interactions with your web artifacts (your marketing site, your documentation, and your READMEs), without introducing cookies or JavaScript.</li> <li>Enriching any existing data you're already collecting on software usage.</li> </ul> <p>In this guide, you will learn:</p> <ul> <li>How to track artifact downloads with Scarf -- we will use a Docker container as an example.</li> <li>How to create a tracking pixel to track views of your package's documentation</li> <li>How to configure Scarf packages </li> </ul>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>You will need to sign up for a Scarf account.   You can sign up with a valid email address or your GitHub account.</li> <li>The container you're looking to track must be published to an existing public registry (e.g., Docker Hub or GitHub Container Registry).   This guide will use the <code>hello-world</code> docker image.</li> </ul>"},{"location":"quick-start/#creating-a-docker-package","title":"Creating a Docker Package","text":"<p>NOTE: This quickstart outlines the process for tracking downloads of a Docker container via Scarf Gateway, but you can track downloads of many other types of OSS artifacts as well, such as files, npm or Python packages. Learn more about other package types on Scarf here.</p> <p>Scarf Gateway is a service that provides a central access point to your containers and packages, no matter where you host them. Users can pull your containers via a Scarf provided domain, or custom domain that you CNAME to Scarf.</p> <ol> <li> <p>Once logged in to Scarf:</p> </li> <li> <p>Click the plus icon in the top right navigation bar, or under the \"Tools\" pull-down, then select <code>New Package</code>. </p> </li> <li> <p>In the first dropdown, click on the package type you would like to create. For this section, you will click <code>Docker</code>. </p> </li> <li> <p>Enter the current pull command for your Docker container.     The Docker command for the <code>hello-world</code> package is <code>docker pull hello-world</code>.</p> <p></p> </li> <li> <p>Optional: You can add a custom domain or use the domain provided by Scarf Gateway. If you choose to create a custom domain, you will need to CNAME your custom domain to the domain provided by Scarf Gateway.</p> </li> <li> <p>Click the <code>Submit</code> button to be redirected to a success screen with some additional information as to what you can do next.</p> </li> <li> <p>Click on <code>Go to your package</code> to view the Package Details. </p> </li> </ol> <p>Now you\u2019re all set to start tracking your Docker images with Scarf. Any time your image is downloaded, Scarf will report some basic information:</p> <ul> <li>System and OS statistics of your users</li> <li>Company information of your users</li> <li>Downloads by versions/tags</li> </ul> <p>In the next section, you will create a tracking pixel that can be added to your project\u2019s documentation or any other web properties associated with your project.</p>"},{"location":"quick-start/#creating-a-tracking-pixel-for-your-package","title":"Creating a Tracking Pixel for Your Package","text":"<p>How the Package-Pixel Pair Works:</p> <ul> <li>Package Distribution: When users install your package, metadata like download source, volume, and timing can be routed through Scarf's infrastructure (e.g., via Scarf Gateway).</li> <li>Pixel Integration: The pixel is included in the package or its associated documentation. When the pixel is triggered, it records usage events, similar to a web analytics tracker.</li> </ul> <ol> <li> <p>Navigate to the Scarf homepage.</p> </li> <li> <p>Pixels can be created from two locations, one is directly from the packages details view. In top menu click on <code>Tools</code> &gt; <code>Packages</code>. Then in the next screen find our package <code>hello-world</code> and click on <code>View details</code>.  on the next screen scroll down to the <code>Tracking Pixel</code> box and click <code>Create pixel</code>.  The second way is to click plus icon in the top navigation, then select <code>New Pixel</code>. </p> </li> <li> <p>You will now see the create pixel page. For this example we'll name our pixel <code>readme</code>.</p> </li> <li> <p>Then attach it to our the newly created <code>hello-world</code> package. (if you came to the <code>create pixel page</code> via <code>package details  page</code> this will be automatically selected) </p> </li> <li> <p>Finally click <code>Submit</code></p> </li> <li> <p>Copy the newly created pixel <code>&lt;img&gt;</code> tag and add it to your website, documentation, or any other web properties associated with your project.</p> </li> </ol> <p></p> <p>For more information on Tracking Pixels see the Documentation Insights section of our docs.</p>"},{"location":"quick-start/#downloading-packages-and-fetching-associated-pixels","title":"Downloading Packages and Fetching Associated Pixels","text":"<p>In this section you will download your package with the pull command found in your package dashboard to start fetching data.</p> <ol> <li>Navigate to your package details view.    </li> <li>Copy the Pull command.</li> <li> <p>Navigate to a terminal on your computer and run the Pull command.     Note: Make sure the docker daemon is running on your computer.</p> </li> <li> <p>Back to the package details view and click on <code>View Analytics</code>. You should now see the Package Insights starting to populate with data. It will usually take 30 minutes and up to 2-3 hours before you see data pulled in.  Every time a user pulls your Docker container images from Scarf Gateway the data in your Package Insights will be updated.</p> </li> </ol>"},{"location":"quick-start/#whats-next","title":"What\u2019s Next?","text":"<p>For more detailed information, please see the relevant documentation;</p> <ul> <li>Packages</li> <li>Scarf Gateway</li> </ul> <p>If you have questions or need help, join our Slack community.</p>"},{"location":"sales-prospecting/","title":"Lead Generation - Scarf\u2019s Sales Prospecting Service","text":"<p>In addition to identifying open-source qualified leads (OQLs), which are the companies already engaging with your OSS, Scarf can help you operationalize that data so you can focus on growing your revenue. </p> <p>Companies familiar with your OSS are more likely to respond to sales outreach; they are truly warm leads who have already tested and are actively using your OSS.</p> <p>By identifying contacts at these companies, you can better prospect for upgrades to a paid version or a commercial support plan. </p> <p>This is where Scarf\u2019s (Lead Generation) Sales Prospecting Service comes in.</p>"},{"location":"sales-prospecting/#what-is-it","title":"What is it?","text":"<ul> <li>In addition to the company names provided by Scarf, users also get a custom report of contacts at those companies who meet your ideal customer profile (ICP) and key buyer personas.</li> </ul>"},{"location":"sales-prospecting/#how-does-it-work","title":"How does it work?","text":"<ul> <li>Scarf\u2019s Prospecting Service is bespoke and highly customizable. Our team pulls your list of actively engaged companies and then narrows it based on your specified ICP and persona.</li> <li>We identify key contacts at those organizations that meet your buyer persona criteria. </li> <li>We aim to provide at least 3 contacts per company interacting with your OSS, working very closely with you to iterate on criteria together.</li> </ul>"},{"location":"sales-prospecting/#how-long-does-it-take-to-get-started","title":"How long does it take to get started?","text":"<ul> <li>There is generally a 1 week lead time to begin prospecting. </li> </ul>"},{"location":"sales-prospecting/#when-are-leads-delivered","title":"When are leads delivered?","text":"<ul> <li>Leads are delivered in a report at an agreed-upon cadence at least once weekly. </li> </ul>"},{"location":"sales-prospecting/#what-information-is-provided-with-the-contacts","title":"What information is provided with the contacts?","text":"<ul> <li>While we can accommodate some customizations to the information provided, generally, the following information is provided for each contact: <ul> <li>First &amp; Last Name</li> <li>Title</li> <li>Contact\u2019s LinkedIn Profile URL</li> <li>Contact Location (City, State, Country where available)</li> <li>Contact Phone (where available) &amp; Email</li> <li>Company Name</li> <li>Company Domain</li> <li>Activity Counts (Downloads, Telemetry, Pixel Views)</li> <li>Company HQ Country</li> <li>Company Size</li> <li>Company Industry</li> <li>Funnel Stage (Level of Engagement)</li> </ul> </li> </ul>"},{"location":"sales-prospecting/#how-do-i-use-it","title":"How do I use it?","text":"<ul> <li>Contacts discovered through Scarf are OQLs for your sales development efforts.</li> <li>We recommend adding contacts to sales outreach campaigns based on the level of engagement (funnel stage). </li> <li>Contacts in early stages, such as Interest or Investigation, likely aren\u2019t ready for a meeting. Instead, we would suggest advertising (targeted to the company) on LinkedIn or other social media where you have a strong presence to create blanket awareness.<ul> <li>Invite them to follow your LinkedIn page, X (Twitter) account, or other social media accounts.</li> <li>Share your content (case studies/blog posts/podcasts, etc).</li> <li>Invite them to sign up for a newsletter.</li> </ul> </li> <li>Contacts in the Experimentation stage are good targets to invite to events such as conferences or webinars you\u2019ll be participating in or attending. </li> <li>Direct, personalized sales outreach is more appropriate for contacts in the Ongoing Usage stage, as these contacts likely have your OSS in use in production and have been actively researching and/or utilizing it for at least 90 days. </li> </ul>"},{"location":"sales-prospecting/#what-if-i-need-to-make-changes-to-my-criteria","title":"What if I need to make changes to my criteria?","text":"<ul> <li>You can change your ICP or buyer personas anytime by updating your Prospecting Service form (available under your Settings menu, Lead Generation) or by contacting your Client Success Manager. <ul> <li>Note: Depending on when they are received, changes to your criteria may take up to 5 business days to incorporate into your lead report. </li> </ul> </li> </ul>"},{"location":"sales-prospecting/#is-it-effective","title":"Is it effective?","text":"<p>To answer this question, we offer customer feedback\u2026</p> <p>\u201cOutbound outreach to Open Source Qualified Leads saw 2x higher response rates as compared to our outreach campaigns without Scarf data\u201d - Dave Donahue, Head of Global Strategy @ Unstructured.</p>"},{"location":"salesforce/","title":"Salesforce","text":""},{"location":"salesforce/#salesforce-requirements","title":"Salesforce Requirements","text":"<ul> <li>A Scarf account with an Organization set-up and an active Premium Subscription.</li> <li>A Salesforce account with API access; API access is included with Force.com, Enterprise, Developer, Performance, and Unlimited Editions. If you are on a different Salesforce plan, you may be required to purchase additional features to enable API access.</li> <li>It is suggested that a dedicated Salesforce integration user be created (Salesforce documentation). However, any user account that has the necessary Salesforce permissions can be used to initiate the connection.</li> </ul>"},{"location":"salesforce/#required-permissions","title":"Required Permissions","text":"<ul> <li>Scarf:<ul> <li>Owner or Admin Permissions</li> </ul> </li> <li>Salesforce:<ul> <li>Permission to read the org ID in Salesforce</li> <li>Permission to \u201cview setup and configuration\u201d</li> <li>Read/write access to standard objects</li> <li>Optional: Permissions to Create Fields on Account Records \u2013 this permission is not required for the CRM sync to function, but Scarf specific Fields must be created in the CRM instance for full metadata to be written.</li> </ul> </li> </ul>"},{"location":"salesforce/#implementation-process","title":"Implementation Process","text":""},{"location":"salesforce/#connection-and-authentication","title":"Connection and Authentication","text":"<ol> <li>Login to Scarf as a user with Owner or Admin permissions.</li> <li>Navigate to <code>Organization Settings</code> -&gt; <code>Integrations</code>.</li> </ol> <ol> <li>Select <code>Connect CRM Instance</code>, confirm you want to sync companies and click <code>Finish linking CRM</code>.</li> </ol> <ol> <li>Click <code>Salesforce</code> from the <code>Select integration</code> menu.</li> </ol> <ol> <li>Review the presented data permissions, and click <code>Next</code>.</li> </ol> <ol> <li>When prompted, enter your Salesforce subdomain, and click <code>Next</code>.</li> </ol> <ol> <li>You will now be prompted to log in to your Salesforce account.</li> </ol> <ol> <li>Once you enter your Salesforce credentials, Scarf will establish a connection with your Salesforce instance.</li> </ol>"},{"location":"salesforce/#synchronization-frequency","title":"Synchronization Frequency","text":"<p>Scarf currently synchronizes with your CRM nightly. The duration of the sync is dependent on the volume of records paired. Manual Company matches are queued for the next nightly sync.</p>"},{"location":"salesforce/#configuring-the-connection","title":"Configuring the Connection","text":"<p>Once the CRM connection has been initialized, the <code>Integrations</code> menu will add three configuration options:</p> <p>Enable Scarf to connect Insights to this CRM Toggling this to off will temporarily disable the CRM integration. While off, no reading or writing will be attempted until the toggle is switched back on.</p> <p>Auto-match to known Accounts from Scarf With the integration enabled, you have the option to set Scarf to use text pattern matching to pair existing CRM Accounts with surfaced Scarf Companies. If the setting is off, then all mapping will be performed manually.</p> <p>Auto-sync When enabled, Auto-Sync ensures that any Scarf Company matched to a CRM Account is automatically included in the next sync cycle. While off, matched companies will not be included in the sync unless manually triggered.</p> <p>Automatically create new Accounts in your CRM You also have the option to set Scarf to attempt to create a new Account record in your CRM when the sync process encounters a Company without a match in the CRM. This will include historical matches as well as any newly surfaced companies.</p> <p> </p> <p>NOTE: By default, all options will be turned on except for Auto-Sync, which will be off. Since Auto-Sync automatically creates records, it is disabled by default to prevent unintended data updates. Users can enable it manually once they have reviewed their setup.</p>"},{"location":"salesforce/#scarf-field-configuration","title":"Scarf Field Configuration","text":"<p>The basic CRM connection allows you to pair Scarf Surfaced Companies with Account records in Salesforce, and optionally to create new Account records when Company Matches are surfaced. In addition to account records, Scarf will attempt to publish metrics to the CRM Account record if a matching Field is found on the account. If no matching Fields are found on an Account Object, Scarf will not update the record. The Fields Scarf will attempt to publish are enumerated here:</p> Field Label (suggested) Field Name (required) Field Type Description Scarf Company Scarf_company_name__c string Company Name as determined by Scarf Enrichment Scarf Domain Scarf_company_domain__c string Primary Internet Domain of the Company Scarf First Seen Scarf_first_seen__c date Date of First Event Scarf observed attributed to this Company Scarf Last Seen Scarf_last_seen__c date Date of most recent Event Scarf observed attributed to this Company Scarf Funnel Stage Scarf_funnel_stage__c string Current Adoption Funnel Stage of the Company Scarf Total Events Scarf_total_events_last_30_days__c number Total observed events in the last 30 days Scarf Total Uniques Scarf_total_unique_sources_last_30_days__c number Unique observed Event Sources (endpoints) in the last 30 days Scarf Events MoM Scarf_total_events_MoM__c number Change in Total Events over the previous Month Scarf Events WoW Scarf_total_events_WoW__c number Change in Total Events over the previous Week Scarf Sources MoM Scarf_total_unique_sources_MoM__c number Change in Unique Sources over the previous Month Scarf Sources WoW Scarf_total_unique_sources_WoW__c number Change in Unique Sources over the Previous Week <p>For a detailed guide on how to make the most of your Salesforce integration, check out our Salesforce Integration Playbook. It walks you through configuring the connection, matching and syncing companies.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This page catalogs common issues and solutions. If you need additional help, don't hesitate to ask us in our community Slack channel.</p>"},{"location":"troubleshooting/#initial-setup","title":"Initial setup","text":""},{"location":"troubleshooting/#i-set-up-a-dockerpythonetc-package-but-my-custom-domain-doesnt-seem-to-be-working","title":"I set up a [Docker/Python/etc] package, but my custom domain doesn't seem to be working.","text":"<p>Make sure you've properly configured your CNAME to <code>gateway.scarf.sh</code>. Use the <code>dig</code> tool to inspect your <code>CNAME</code>. You should see something like:</p> <pre><code>~ \u276f\u276f\u276f dig downloads.avi.press\n; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; downloads.avi.press\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 45111\n;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n;; QUESTION SECTION:\n;downloads.avi.press.       IN  A\n\n;; ANSWER SECTION:\ndownloads.avi.press.    1799    IN  CNAME   avi.gateway.scarf.sh.\navi.gateway.scarf.sh.   900 IN  CNAME   a9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com.\na9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com. 60 IN A 54.203.228.158\na9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com. 60 IN A 54.186.175.150\na9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com. 60 IN A 52.32.4.234\n\n;; Query time: 131 msec\n;; SERVER: 50.0.1.1#53(50.0.1.1)\n;; WHEN: Sun Dec 03 09:12:07 PST 2023\n;; MSG SIZE  rcvd: 221\n</code></pre> <p>Another factor is domain verification. On package creation you'll be prompted to verify your custom domain, if it hasn't been verified just yet.</p> <p>Use <code>dig</code> to inspect the verification TXT record. You should see something like</p> <pre><code>~ \u276f\u276f\u276f dig txt _scarf-sh-challenge-ORGANIZATION.org.example.com\n\n;; ANSWER SECTION:\n_scarf-sh-challenge-ORGANIZATION.org.example.com. 300 IN TXT \"NDVTRE6YP25CAM2PHR2B\"\n</code></pre> <p>Remember to substitute <code>ORGANIZATION</code> for your account name and <code>org.example.com</code> for your custom domain.</p>"},{"location":"troubleshooting/#my-package-is-setup-up-but-when-i-pull-im-seeing-the-error-tls-failed-to-verify-certificate-x509-certificate-is-valid-for-ingresslocal","title":"My package is setup up, but when I pull I'm seeing the error: <code>tls: failed to verify certificate: x509: certificate is valid for ingress.local</code>","text":"<p>This error means Scarf is still propagating your custom DNS setup across our datacenters globally. Typically this takes up to 30 minutes or up to 2-3 hours the first time you configure your custom domain. If you've been waiting longer and are still seeing this issue, please let us know.</p> <p>You can also see your package's domain verification status in the details overview. Expand the section for Verification to also see the CNAME and certificate status.</p>"},{"location":"troubleshooting/#my-downloads-are-working-but-im-still-not-seeing-the-data-in-my-dashboard","title":"My downloads are working but I'm still not seeing the data in my dashboard","text":"<p>Typically it takes up to 30 minutes or up to 2-3 hours for any given event to be reflected in your dashboard. We occasionally experience processing delays if our system is experiencing high volume of events, but your data isn't lost. If you're noticing unexpected delays, check our Community Slack for updates on processing delays or to report one.</p>"},{"location":"troubleshooting/#i-have-set-up-a-docker-collection-and-the-downloads-are-working-but-package-entries-are-not-being-created","title":"I have set up a Docker collection, and the downloads are working, but package entries are not being created.","text":"<p>This also sometimes takes up to 30 minutes or up to 2-3 hours, and is occasionally delayed if our system is impacted by data processing pipeline delays due to high volume. If you are still not seeing your collection be created, get in touch with us.</p>"},{"location":"troubleshooting/#i-want-to-update-a-docker-package-to-point-to-a-different-registry-but-am-getting-a-public-domains-for-docker-packages-may-only-point-to-a-single-backend-registry-at-a-time-error-how-can-i-fix-this","title":"I want to update a Docker package to point to a different registry, but am getting a <code>Public domains for Docker packages may only point to a single backend registry at a time.</code> error. How can I fix this?","text":"<p>Due to the way the OCI spec is defined, Scarf is only able to map your public domain to a single backend registry. To point to multiple registries, you need to use multiple public domains.</p>"},{"location":"troubleshooting/#how-can-i-update-the-backend-registry-for-all-of-my-containers","title":"How can I update the backend registry for all of my containers?","text":"<p>See <code>Tools</code> -&gt; <code>Packages</code> -&gt; <code>Management</code> to bulk configure your packages. If you have a Collection set up, you'll also need to update it.</p>"},{"location":"troubleshooting/#where-can-i-generate-an-api-access-token","title":"Where can I generate an API access token?","text":"<p>API tokens are managed at the user level and can be found in your account settings here.</p> <p>To locate your API token quickly, open the page and use Cmd + F (or Ctrl + F on Windows) to search for \"API\"\u2014you\u2019ll find it about halfway down the page.</p>"},{"location":"troubleshooting/#data-and-analytics","title":"Data and analytics","text":""},{"location":"troubleshooting/#i-downloaded-an-artifact-and-scarf-is-showing-my-download-as-the-wrong-company","title":"I downloaded an artifact and Scarf is showing my download as the wrong company","text":"<p>IP -&gt; Company matching is an imperfect approach and incorrect matches do happen. A few things can help understand low-confidence matches:</p> <ul> <li>You can disable \"low confidence\" companies via the toggle at the top of your company match table.</li> <li>Check the confidence for any individual event through the company activity view (click on the company) and see the \"Events\" section.</li> </ul> <p>Over time, low confidence scores are outweighed by observing company traffic in aggregate over a longer period of time rather than over-indexing on a single one-off event.</p> <p>If you're seeing persistent issues with a particular company or IP address, let us know so we can update our records accordingly and ensure high accuracy of matches.</p>"},{"location":"troubleshooting/#scarf-gateway","title":"Scarf Gateway","text":""},{"location":"troubleshooting/#dns-based-network-blocking-tools-seem-to-be-blocking-memy-users-from-pulling-artifacts-through-scarf-gateway","title":"DNS-based network blocking tools seem to be blocking me/my users from pulling artifacts through Scarf Gateway.","text":"<p>Some DNS-based network blockers (eg, Pi-hole) are able to pull in analytics-specific block-lists, which may contain Scarf URLs which cause downloads through the gateway to fail. If one of these lists is blocking downloads through Scarf Gateway, you'll need to explicitly allow <code>*.scarf.sh</code> in your tool configuration.</p>"},{"location":"understanding-your-insights/","title":"Making Sense of Your Scarf Insights","text":"<p>Your Scarf dashboard uses various technical terms that are important to understand.</p>"},{"location":"understanding-your-insights/#unique-sources","title":"Unique Sources","text":"<p>Scarf denotes how many <code>sources</code> or <code>unique sources</code> were behind any given number of events. Because open source activity happens anonymously, Scarf's ability to form a stable anonymous ID for a given user / source of traffic can happen at multiple levels of granularity, and therefore are given different types of IDs.</p>"},{"location":"understanding-your-insights/#origin-ids","title":"Origin IDs","text":"<p>An <code>origin_id</code> is the most granular of Scarf IDs, and the default notion of unique sources throughout the platform.</p> <p>An <code>origin_id</code> is a salted hash of every identifier available to Scarf in an HTTP request: the IP address, the user agent, and any other identifying headers that might be available.</p> <p>An individual developer may map to multiple <code>origin_ids</code> as they change IP addresses, or use different programs on their machine to make requests. Thus it is good to consider it a ceiling or slightly higher estimate of how many people are behind the activity you are tracking.</p> <p>This makes <code>origin_id</code>s a useful way to approximate individual developer activity, but they are not a perfect one-to-one mapping to people. Instead, you can think of them as the most fine-grained view Scarf provides. They are helpful for estimating upper bounds on unique developers/deployments.</p>"},{"location":"understanding-your-insights/#endpoint-ids","title":"Endpoint IDs","text":"<p>An <code>endpoint_id</code> is the least granular Scarf source ID, which is a salted hash of just the IP address. Unlike <code>origin_id</code>s, which consider multiple request attributes, <code>endpoint_id</code>s group together all activity that appears to come from the same network location.</p> <p>Because many developers in an organization might share the same IP (for example, when working behind a corporate NAT or build server), multiple people / machines can collapse into a single endpoint_id. Conversely, a single individual may generate multiple <code>endpoint_id</code>s if they work from different networks, such as switching between home, office, and cloud environments.</p> <p>This makes <code>endpoint_id</code>s a good way to reason about unique network sources, but they are not a direct proxy for individual people. Instead, you can think of them as a middle ground: less noisy than <code>origin_id</code>s but still more fine-grained than company-level resolution.</p>"},{"location":"user_best_practices/","title":"User Guide &amp; Best Practices","text":""},{"location":"user_best_practices/#introduction","title":"Introduction","text":"<p>This is a user guide to best practices when using Scarf.  Consider this not only a guide but also an FAQ.  </p> <p>Currently this guide contains:</p> <ol> <li>How to use Scarf Data in existing  sales and marketing efforts<ol> <li>Events you should be tracking</li> <li>The goal is ongoing usage </li> <li>How to use Scarf to infer ongoing usage </li> <li>Basic lead scoring with Scarf</li> <li>Sample customer journey </li> <li>What to do with companies identified by Scarf</li> <li>Common ways to inject Scarf into existing sales/marketing activities </li> <li>Common ways for startups to build their first sales and marketing processes </li> </ol> </li> <li>How to use confidence intervals</li> <li>Best Practices to track multiple projects and packages<ol> <li>Handling different projects</li> <li>Handling different versions</li> <li>Handling different platforms</li> <li>Container best practices</li> <li>Variables </li> <li>Pixels for each project  </li> </ol> </li> <li>Tracking external link clicks</li> </ol>"},{"location":"user_best_practices/#how-to-use-scarf-data-in-existing-sales-and-marketing-efforts","title":"How to use Scarf data in existing sales and marketing efforts","text":""},{"location":"user_best_practices/#events-we-should-be-tracking","title":"Events we should be tracking:","text":"<p>There are 3 events we would suggest everyone track. </p> <ul> <li>Downloads/Pull events</li> <li>Views of documentation</li> <li>Views of content/website (pages, blogs, tutorials)</li> </ul> <p>The first is downloads (no matter if it's direct on your website, via a container registry, or via public repositories. Scarf allows you to track and aggregate downloads across all these different channels). This is probably the most valuable action. A download means someone has not only some interest in your product but enough interest to try it out.</p> <p>There are three aspects to downloads which you should be paying attention to:</p> <ul> <li>The number of downloads from unique sources at a company - more than one machine/source downloading is good.</li> <li>The volume of downloads over a time period at the company - you want to see continued downloads over time, this implies ongoing usage.</li> <li>Is the company downloading newer versions of the software over time - this is gold as it implies not only are they downloading but they are trying to keep things up to date and implies the software is critical enough to have maintenance procedures around it.</li> </ul> <p>The second on the list is documentation views. People using your software will often have questions about how to install, use, and upgrade the software. You will see patterns evolve over time in the usage of the software docs depending on the software. Initially you will see more traffic to the installation and setup sections. This coupled with download events is a great indicator of testing or trying things out. Then users will evolve more into troubleshooting or optimization views. See more page views shift to this is normal. Then you should see views to readmes or upgrade pages as they settle into maintenance and sustain mode. Ultimately I would be looking for views over an extended period of time to ensure they are invested and not just kicking the tires.  </p> <p>The third on the list is content/website views. Not all views will be coming from docs, in fact for commercial purposes there are certain pages on your website that may be highly predictive of potential interest in becoming a customer (i.e. the pricing pages). But I recommend looking for ongoing views and traffic hitting blogs and other news on the product and upcoming releases.  </p> <p>For each of the events, I would recommend breaking down all the activities into either good/better/best or low/medium/high impact events. </p> <p>Here is a suggested list of criteria when it comes to classifying events:</p> Event GOOD BETTER BEST Downloads 1 or more downloads in a week. More than 1 download over a 30-day period. Multiple downloads over a 90-day period, including incremental downloads of new versions. Documentation Views Repeated views on installation and setup instructions. Documentation views spanning more than 30 days from multiple sources. More than just install page views.    Documentation views spanning more than 90 days from multiple sources. Doc views on upgrades and maintenance procedures. Website Traffic Multiple pages visited and viewed by 1 company over a week period. Multiple pages visited and viewed by 1 company over a 30-day period. Page views to medium value content. I.e. Reading technical blogs, visiting forum pages, product feature pages."},{"location":"user_best_practices/#the-riskiest-but-most-valuable-metric-ongoing-usage","title":"The Riskiest But Most Valuable Metric: Ongoing Usage","text":"<p>While the three activities above are straightforward and generally not viewed with too much concern, there is a fourth activity or metric you can (and probably should) track.  An essential, albeit controversial, activity that serves as a highly valuable metric for any organization seeking to understand the usage patterns of its software - the use of 'call-home' functionality, also known as ongoing usage tracking. The call-home functionality is a mechanism within your software that sends a signal, or a 'ping', back to a designated server or gateway. This signal provides you with real-time information about your software's usage in live production environments, surpassing the insight level gained from just tracking downloads.</p> <p>While download data can indicate interest and repeated use of your software, the ongoing, consistent 'ping' or call-home activity serves as a definitive predictor of your software's actual usage. Consider this the 'Nirvana' of metrics for your projects, the golden standard that allows you to measure the exact magnitude of your active install base and the frequency of software usage and deployment.</p> <p>However, implementing this mechanism requires a degree of technical adaptation. Platforms like Scarf, for instance, offer this capability out of the box. But to make full use of it, you'll need to adjust your application accordingly. There are different ways to accomplish this; for JavaScript applications, a package called <code>scarf-js</code> can be used. Alternatively, a lightweight, background 'ping' or activity back to a Scarf gateway event can be employed. This ping can be triggered when your application starts up, is used, or at any other specified event.</p> <p>In essence, your application would asynchronously call back to the gateway website, which doesn't return any data but rather tracks that the application was active. If you can successfully implement this, you can then monitor the number of unique pings over a certain period from various sources. This is incredibly valuable for lead scoring as it provides consistent, ongoing proof of life from these systems, making it the most valuable event or activity you could track.</p>"},{"location":"user_best_practices/#how-to-use-scarf-to-infer-ongoing-usage","title":"How to use Scarf to infer ongoing usage","text":"<ul> <li>Look for companies activities over an extended period of time. Repeated downloads over 30/90/180 days is a very predictive indicator of ongoing reliance </li> <li>Look for companies who download incremental versions of your software over time</li> <li>Look at documentation views over time, especially upgrade docs and operational docs from the same user/company</li> <li>Consider adding a ping or call back within your software to an empty page behind a Scarf Gateway URL, this will allow you see these calls within Scarf.  </li> </ul>"},{"location":"user_best_practices/#basic-lead-scoring-and-customer-journey-mapping-with-scarf","title":"Basic lead scoring and customer journey mapping with Scarf","text":"<p>Not all people visiting your website and downloading your software are equally likely to become customers. In fact you will find 3x, 5x, or even 10x more drive by traffic as you will find those interested in commercial offerings. To become efficient at finding which companies and users you should focus on, let's explore the concept of \u201clead scoring\u201d. </p> <p>Lead scoring is a methodology used by sales and marketing departments to determine the worthiness of leads, or potential customers, by assigning values to them based on their behavior relating to their interest level in products or services. These values, or scores, are derived from a variety of factors like the professional information they've submitted, how they've engaged with the company's website, or their response to marketing efforts. The purpose of lead scoring is to prioritize leads who are more likely to convert into customers, allowing teams to focus their time and resources effectively. It's a vital part of creating an efficient sales and marketing strategy.</p> <p>If you've already established a lead scoring system and are utilizing marketing software, consider events in open-source channels as additional data points to further qualify or uncover leads. For instance, a software download could be treated as a high-value (or high-score) activity, whereas a documentation view might be scored similarly to other website visits. It could be beneficial to categorize documentation and page views into high, medium, and low scoring pages, as certain pages (like pricing or install pages) can be more predictive and valuable than others.</p> <p>The key distinction between traditional lead scoring and the incorporation of open-source download and traffic data lies in the summarization of data at the company level, requiring decisions on scoring criteria. Most marketing lead management tools track users based on sign-ups, cookies, or other mechanisms, capturing specifics such as Matt from Scarf signing up for a webinar. With data from anonymous sources, the best we can do is infer that someone from Scarf has downloaded your software.</p> <p>The question then becomes: if you know Matt attended a webinar and works at Scarf, does the Scarf download make Matt a more qualified lead? Or should you shift your focus to other individuals at Scarf, possibly higher up in the management hierarchy? There's no absolute right or wrong answer, but my inclination would be to enrich the data of the known user who has already shown interest.</p> <p>Additionally, it's important to note that software downloads can often be automated. Seeing ten downloads a day doesn't necessarily equate to thousands of servers or the potential for a massive deal. This data needs to be scrutinized, at the very least, by examining the unique systems or origins from where these downloads originate.</p> <p>Lastly, when incorporating open-source downloads and traffic data, the timeline of events becomes critical. A single download could mean anything, but consistent downloads over several months, especially with each new version release, suggests a real, potentially highly qualified user.</p>"},{"location":"user_best_practices/#customer-journey-example-with-scarf","title":"Customer journey example with Scarf","text":"Different Phases of Interest Description Events Action Passive interest: Hello World Someone discovered or visited your website. They may or may not have any interest in your software or projects. Web traffic to docs or websites over the course of 1 or 2 days. I would not take any action here. Intrigued in your software: This looks interesting Someone takes more than a drive by interest in your software.  They are truly interested in what you have. Documentation views. Looking at install docs and/or feature lists. Typically this is over multiple days. I would consider promoting content tothat company's target audience (engineers?) on other external channels. Trial &amp; Exploration: Let me try this out They move from just learning about the software to actually downloading it. Documentation and website views of high value pages along with at least 1 download event.You still see this traffic over multiple days but typically over a week or two. I would recommend promoting blogs or how-tos that are interesting to this group of customers. You could even promote this content directly on your website when these visitors appear. Testing &amp; Evaluation: I wonder if I can usethis for this project Now someone is looking deeper into this and is starting to either use it or seriously consider it. Sustained page views and multiple downloads over a month period. Here is where additional content promotion is still a good idea, but where there is a strong commercial offering targeting these customers can be effective. Implementation &amp; Reliance: This is cool, let's use this in production Someone is using this over a longer period of time and looks to be beyond merely testing/trying out. If you see activities (both downloads and traffic) spread over a 90 day period, there is a high confidence in their usage in a critical space. This is the best time to seek out conversations. - Cold outreach - Targeted ads - Seek out devs at conferences Maintenance &amp; Ongoing Upkeep: Keeping things updated and safe Someone has been using your software for months and is grabbing new versions of your software and reading readmes or regular updates (like blogs). Look for activities over months (3-12 months), with downloads of multiple versions. Also look for views on readmes or product specific content (blogs, etc). This is the best time to seek out conversations. - Cold outreach - Targeted ads - Seek out devs at conferences Waning Interest &amp; Potential Churn: Uh oh\u2026 this user is at risk Usage is dropping and there is risk that this user may turn from an active user to a former user. If you see massive drop offs in traffic and downloads over a 30 day period this sends up red flags."},{"location":"user_best_practices/#what-to-do-with-companies-identified-by-scarf","title":"What to do with companies identified by Scarf","text":"<p>Effectively employing this data requires a strategic and tailored approach to meet the unique needs and goals of each organization. Below are some general recommendations that apply to most situations:</p> <ul> <li>Understand Your Audience: Use download data and website traffic information to build a deeper understanding of your audience. This involves analyzing who is downloading your software, viewing your documentation, and browsing your website. With this information, you can enrich your existing leads, score potential ones, and build a well-informed customer profile.</li> <li>Customize Your Approach: Once you've gathered and analyzed your data, tailor your marketing and sales processes to align with your findings. Whether you're focusing on sales/marketing or product, align your strategies and activities with the preferences and behaviors of your users. This could involve adjusting lead scoring based on the activity level or nurturing potential users to become ongoing ones.</li> <li>Integrate Data with Existing Processes: Integrate your new data with your existing sales, marketing, and customer success processes. For instance, using download patterns to assess the churn potential can help you anticipate and mitigate customer attrition.</li> <li>Adopt a Nurturing Approach: When it comes to new or startup sales/marketing processes, take a nurturing approach. This means guiding users through a lifecycle where they are initially familiarized with your software, then nurtured to become regular users, and eventually led to become paid customers.</li> <li>Leverage Social Media: Social media platforms offer targeted marketing opportunities. Platforms like LinkedIn allow you to aim your promoted content towards specific companies and job titles.</li> <li>Optimize Content: Make use of your existing content and create new content based on where your users and companies are spending the most time. Calls-to-action (CTAs) on these pages can effectively guide users through your marketing funnel.</li> <li>Community Engagement: Encourage users to join your community, participate in events, and engage in discussions. Community engagement can serve as a powerful tool for user retention and organic growth.</li> <li>Monitor and Adapt: Regularly assess the effectiveness of your strategies and be willing to make necessary adjustments. The digital landscape is ever-evolving, and your strategies should be adaptable to accommodate these changes.</li> </ul>"},{"location":"user_best_practices/#common-ways-to-inject-scarf-into-salesmarketing-activities","title":"Common ways to inject Scarf into sales/marketing activities:","text":"<p>Existing sales and marketing activities can be significantly enriched by smartly integrating download data and website traffic information. By revising your lead scoring methodology to include new data points such as software downloads and page visits, you can ensure that you are incorporating the latest indicators of interest from your audience. The enhanced lead scoring will provide a more nuanced understanding of your prospective customers, paving the way for more targeted and effective outreach.</p> <p>Use the company lists generated from this data in your cold outreach activities. By focusing your outreach efforts on these companies, you are targeting organizations already demonstrating interest, thereby increasing your chances of gaining a receptive audience. These lists can also serve as a valuable resource for your Business Development Representatives (BDRs), equipping them with a list of vetted leads, saving time and improving their efficiency.</p> <p>Additionally, using this data, you can strategically plan meetings at conferences, events, and similar networking platforms with representatives from companies using or showing interest in your product. This targeted networking can lead to higher-value interactions and ultimately result in stronger leads.</p> <p>Incorporating the pattern of downloads into your customer success and renewal operations can provide a more comprehensive customer overview. Such insights into customer behavior can inform your renewal strategies, equipping you with necessary foresight to address potential issues and ensure customer satisfaction. Moreover, the data can be a key indicator of potential churn risks, allowing you to proactively manage customer retention by identifying and addressing their concerns before they choose to discontinue your service.</p> <ul> <li>Use the data to enrich your existing set of leads. You can add additional events to your lead scoring process.</li> <li>Use the data to build a highly qualified list for outreach activities. Target companies that are using your software or are interested in your software.</li> <li>Use this data to inform your marketing strategies. For example, prioritize individuals from companies that have shown interest in your software at meetings, conferences, and events.</li> <li>If you have a fully fleshed out sales, marketing, and customer success process, use the data to assess churn risk.</li> </ul>"},{"location":"user_best_practices/#common-ways-for-startups-to-build-their-first-salesmarketing-process-with-scarf","title":"Common ways for startups to build their first sales/marketing process with Scarf:","text":"<p>For startups or companies initiating new sales and marketing initiatives, creating a lightweight growth engine that nurtures potential users can be the key to driving growth. Setting up a lifecycle or nurture campaign can guide potential users through your marketing funnel, providing them with the right content at the right time to foster interest and engagement.</p> <p>Promoted content can be a powerful tool in these campaigns. Aimed at users in the early stages of engagement, this content can educate users about your software, showcasing its features and benefits and encouraging them to explore it further. As these potential users turn into ongoing users, you can begin to introduce promoted content, offers, and cold outreach to convert them into paying customers.</p> <p>Understanding the customer journey is crucial in a startup or new marketing environment. By mapping out this journey and identifying combinations of events and thresholds, you can strategize when to increase or decrease marketing activities for optimal effect. This dynamic approach can keep your marketing efforts agile and responsive to user behavior.</p> <p>Social media platforms like LinkedIn offer a targeted way to reach specific companies.</p> <ul> <li>Use this data to build a lightweight marketing and growth engine.</li> <li>Approach the process as a life cycle or nurture-type campaign. Nurture potential users until they become productive users.</li> <li>Use promoted content targeted towards companies that are downloading or have looked at your documentation.</li> <li>Once users are actively using your software, shift the focus to ongoing maintenance and new releases. Then, start introducing your paid offerings or services.</li> <li>Use social media to engage potential users, specifically for companies you identified</li> <li>Integrate the scarf platform into your existing community activity to help nurture and guide potential users.</li> </ul>"},{"location":"user_best_practices/#how-to-use-confidence-intervals","title":"How to use confidence intervals","text":"<p>In your Scarf dashboards you will often see a confidence flag associated with events and companies.</p> <p></p> <p>The confidence is a measurement of Scarf's confidence in the IP/metadata -&gt; organization match for each event. Some of our metadata providers like Clearbit provide their own confidence scores and Scarf will take those into account, but we also account for what other providers say. We will make our own adjustments in many cases, for instance, if there is disagreement between the different data providers we use, or if we find irregularities in the metadata.</p> <p>Confidence intervals have 2 data points associated with them. The first is the overall flag which is low (red), medium (yellow), and high (green) confidence. This gives you a quick way to associate high-probability matches with low ones. When looking into the flags, you will find a percent (%) of confidence associated with each company and event, and these percentages can be used to differentiate further which companies and events to prioritize.</p> Confidence Description How to Use Low Low confidence matches, based on available data we suspect these events are associated with this company, but can not be 100% sure. We do not recommend taking direct action on small numbers of low confidence matches.  Consider these to be very low quality leads, if leads at all. This data however is valuable if correlated with outside data for this organization.  For instance if you know this organization is active in the community or if you see multiple low confidence leads over the course of weeks or months from unique end points, this may indicate these are higher quality then our data suggests. Medium These events have an above average chance of being from associated companies.  We have been able to match multiple checks in the metadata and our external providers have an above average confidence in their match. Medium confidence matches should be considered second tier data, with leads being followed up after processing higher condfidence data. This data is valuable in enriching other data source and we would feel confident in using it for trends, analysis, and as part of a broader customer intelligence effort. In part of an ABM (account based marketing) strategy we would feel confident in using these matches correlated with a list of targeted accounts. This is also a good list of organizations for BDR and prospecting activities. High The events and organizations that have a high confidence interval mean that we have multiple high probability indicators of a match to an organization for these events. High confidence matches provide the highest quality data. We are confident in people using this data for their sales pipelines, lead scoring, etc. These records could be integrated into exsiting tools to give a complete picture of a customers journey <p></p>"},{"location":"user_best_practices/#best-practices-to-track-multiple-packages-or-projects","title":"Best practices to track multiple packages or projects","text":"<p>Many of our customers offer downloads of multiple different open source projects, different versions, or downloads for different platforms. There are some best practices we have found useful for many of our customers when faced with dozens or even hundreds of unique packages. Your decisions on how to handle multiple packages, projects, or versions ultimately will come down to a.) how you want to report the data and b.) personal preference. </p> <p>Keep in mind you can export data and report on a variety of metrics by package, variable, etc. However, if you want to get quick analytics using the Scarf dashboards, reporting is done for all your packages (global), an individual package, or a specific pixel. You can see metrics for each variable under a package or pixel. As of July 2023, variable reporting on a package or pixel is limited to a single dimension. i.e.  I can see a report for <code>{variable1}</code> or <code>{variable2}</code> for a package or pixel, but I can not see data for <code>{variable1}</code> correlated with <code>{variable2}</code>. You can, of course, do this correlation and analysis by exporting and using your own analytics tool. Keep this in mind as you build your packages and routes.  </p>"},{"location":"user_best_practices/#handling-different-projects","title":"Handling different projects","text":"<p>You may have different open-source projects you support and ship to the community. For these we recommend setting up a new package for each project.</p>"},{"location":"user_best_practices/#handling-different-versions","title":"Handling different versions","text":"<p>In the gateway, we recommend setting up a minimum of 1 package per project. Each package created within Scarf should have 1 or more routes. i.e., <code>http://companyname.gateway.scarf.sh/projectname/file.gz</code> would be the minimum. We recommend using variables for each version you are currently supporting, i.e., <code>http://companyname.gateway.scarf.sh/projectname/{version}/file.gz</code> or <code>http://companyname.gateway.scarf.sh/projectname/file.{version}.gz</code> this allows you to update and release versions without having to create new routes for each. This also enables reporting in the Scarf dashboard to track downloads and growth of each version.  </p> <p>Some people have found it easier to create routes for new major versions, but you could also use multiple variables for this. I.e.</p> <ul> <li><code>http://companyname.gateway.scarf.sh/projectname/V1/file.{minorversion}.gz</code></li> <li><code>http://companyname.gateway.scarf.sh/projectname/V2/file.{minorversion}.gz</code></li> <li><code>http://companyname.gateway.scarf.sh/projectname/{majorversion}/file.{minorversion}.gz</code></li> </ul> <p>Depending on your needs, you could create a new package for each major version, but it is not required.</p>"},{"location":"user_best_practices/#handling-different-platforms","title":"Handling different platforms","text":"<p>Similar to handling different versions, you can use variables if you are shipping different package types or for different platforms. So instead of:</p> <p><code>http://companyname.gateway.scarf.sh/projectname/RHEL5/{majorversion}/file.{minorversion}.gz</code> and  <code>http://companyname.gateway.scarf.sh/projectname/RHEL6/{majorversion}/file.{minorversion}.gz</code></p> <p>You could do the following:</p> <p><code>http://companyname.gateway.scarf.sh/projectname/{osversion}/{majorversion}/file.{minorversion}.gz</code></p>"},{"location":"user_best_practices/#containers","title":"Containers","text":"<p>For containers, we recommend setting up a \"Collection\" to sit in front of your entire namespace, i.e., <code>company/*</code> on Docker Hub or your preferred container registry. Collections automatically sync and keep up to date with container registries making it easy to release new versions without having to worry about Scarf being up to date with new releases. To learn more, check out the collections docs</p> <p>You can use variables just like you do for other downloads. </p>"},{"location":"user_best_practices/#variable-order","title":"Variable order","text":"<p>No matter what kind of package you are using, we recommend ensuring your different file packages have distinct, concrete prefixes in their route to prevent ambiguous overlap in redirect config. For instance: </p> <p><code>http://companyname.gateway.scarf.sh/{os}/{os_version}/packagename/{filename}</code> </p> <p>Technically would work, but this will limit reporting and cause overlapping issues. As a result, we would recommend hardcoding routes to the attributes you want to report on first in your route, with variables stored towards the back of the route. So, for instance : </p> <p><code>http://companyname.gateway.scarf.sh/packagename/{os}/{os_version}/{filename}</code>. </p> <p>Doing so will allow you to report on each package name separately, with slices broken out by each variable as needed.  </p>"},{"location":"user_best_practices/#unique-pixels-for-each-projects-docs","title":"Unique pixels for each projects docs","text":"<p>While optional, it can be a good idea to make unique pixels specific to docs pages pertaining to the package to easily correlate web/docs traffic pertaining to certain packages. Ultimately this is more of a convenience when it comes to analyzing the data, but it's not at all necessary.</p> <p>Depending on your needs, here are two strategies you may find useful:</p>"},{"location":"user_best_practices/#pixels-for-lead-gen","title":"Pixels for lead gen","text":"<p>If you have different types of content, some content or pages may, in fact, be more valuable for users than others. In this case, one strategy may be to create multiple pixels for different types of pages. Consider this:</p> <p>Create 4 pixels:</p> <ul> <li>General traffic<ul> <li>Embed the general traffic pixel on all pages.  </li> </ul> </li> <li>high value <ul> <li>Embed the high value on your pricing pages, support pages, and other highly desirable docs/website pages.  </li> </ul> </li> <li>medium value<ul> <li>Embed the medium value pixel on your installation and setup docs, tutorials, or other mid-level docs. </li> </ul> </li> <li>low value<ul> <li>Embed the low-value pixel on everything else.  </li> </ul> </li> </ul> <p>Now you will be able to classify and score users' activities based on what sort of content they viewed. You can even bake this into your existing lead-scoring system.  </p>"},{"location":"user_best_practices/#overlapping-pixels-for-tags","title":"Overlapping pixels for tags","text":"<p>You can embed multiple pixels on the same page for different reasons to facilitate more detailed reporting. For instance, you may want to create one pixel for each project, but you may also want to create a pixel for just specific types of content on your website or elsewhere on the web. For instance, maybe you want everyone looking at blogs or tutorials on a critical feature to be tracked and have metrics reported on.  </p>"},{"location":"user_best_practices/#tracking-external-link-clicks","title":"Tracking external link clicks","text":"<p>A gateway route does not have to link back to a file to download; it can also forward traffic to a URL and track the traffic who clicked the link. This allows you to track who is clicking on links in social media, watching videos, clicking on links in external content, etc. We created a tutorial on this here:</p>"},{"location":"user_best_practices/#excluding-certain-events-from-your-analytics","title":"Excluding certain events from your analytics","text":"<p>Some traffic can be noise that you want to fully exclude from your results without having to set filters manually. To set persistent filters heads to your organization settings.</p>"},{"location":"user_best_practices/#excluding-all-known-bot-traffic","title":"Excluding all known bot traffic","text":"<p>Set this toggle to have Scarf completely suppress all events from known bot user agents. Contact the Scarf team if you are seeing user agents that should be added to our list.</p> <p></p>"},{"location":"user_best_practices/#excluding-traffic-by-specific-user-agent","title":"Excluding traffic by specific user agent","text":"<p>Set this toggle to have Scarf completely suppress all events from known bot user agents. This is one approach to filter out internal traffic from yourself or your team, by simply adding a known string to your user agents as you download your artifacts or send telemetry.</p> <p></p> <p>Adding <code>REMOVE_ME</code> will remove any user agent containing the literal string <code>REMOVE_ME</code> from your Scarf analytics results. At this time, only simple substring matches are supported.</p>"},{"location":"web-traffic/","title":"Scarf Pixels","text":""},{"location":"web-traffic/#how-it-works","title":"How it works","text":"<p>Scarf gathers web traffic insights via a simple transparent, cookie-free, tracking pixel. You copy an <code>&lt;img&gt;</code> tag from Scarf into your project's README, docs, website, or any other web property. Any time a user views content with your Scarf pixel, Scarf will look up any business metadata associated with the address and surface that information to you (and only you) via your Scarf account. Scarf does not store the IP address itself, so no personally identifiable information is retained.</p> <p>Not relying on cookies has a some powerful effects:</p> <ul> <li>Scarf pixels don\u2019t just work on your website / domain, but anywhere your content is viewed. You\u2019re able to track visits to your documentation on 3rd party sites like your package registry provider, or when your docs are rendered locally on a user\u2019s machine.</li> <li>No cookie banners are needed, and your users are never tracked from a Scarf pixel as they continue to surf the web.</li> </ul>"},{"location":"web-traffic/#creating-a-pixel","title":"Creating a pixel","text":"<p>Head to your Scarf dashboard and click the + in the top-right corner, then click <code>New Pixel</code>. Give your pixel(s) a name, select an Owner to manage its scope (your organization is recommended), and optionally attach it to a package you manage on Scarf. This package attachment is optional and is solely used for visualizing the statistics for a pixel and a package together on the same page within the Scarf dashboard.</p> <p></p> <p></p> <p>Pro Tip: All new pixels default to \u201cMedium\u201d importance. It\u2019s a good idea to let Scarf start capturing data before determining if that needs to change.</p> <p>By default, pixels are hosted in <code>static.scarf.sh</code>. You can use your own domain by filling in the domain field.</p> <p></p> <p>After creating the pixel with a custom domain, instructions will be provided on how to verify your domain.</p> <p></p> <p>The speed of domain verification will depend on how fast your DNS provider propagates the domain changes. When your domain is verified you should see this indicator.</p> <p></p> <p>Once created, you can access this Pixel in the Tools dropdown, under Pixels. Here, you will see a full list of all your existing Pixels.</p>"},{"location":"web-traffic/#tracking-pixel-custom-domains","title":"Tracking Pixel Custom Domains","text":"<p>Multiple domains can be added to a tracking pixels. In the same menu, tracking pixel domains can be removed.</p> <p></p>"},{"location":"web-traffic/#embedding-and-using-the-pixel","title":"Embedding and using the pixel","text":"<p>Head to your Scarf dashboard and, in the Tools dropdown, select Pixels. Click Copy Pixel Snippet to copy the <code>&lt;img&gt;</code> tag to your clipboard, and then paste the tag into your project's README, docs, and any other web properties where you want to gather insights into who is using your documentation pages.</p>"},{"location":"web-traffic/#google-tag-manager-gtm","title":"Google Tag Manager (GTM)","text":"<p>Using Scarf pixels with Google Tag Manager works easily but requires one additional configuration step beyond simply dropping in your pixel URL.</p> Field Value Example Tag Type Custom Image Tag -- Image URL <code>&lt;your Scarf pixel URL&gt;&amp;Page={{Page URL}}</code> https://static.scarf.sh/a.png?x-pxid=123&amp;Page={{Page URL}} Triggering Page View - All Pages -- <p>This extra step is because GTM's injection of the pixel tends to tamper with the <code>referrer</code> header that Scarf relies on in order to infer what page is being loaded. We work around this by explicitly adding it to the URL's query parameters.</p> <p>If for any reason, you need to use a different variable key besides <code>Page</code>, you'll want to configure a custom variable override for the <code>Page</code> parameter in your org settings, to whatever key you'd like to use. This ensures Scarf treats your parameter as the page rather than a normal arbitrary piece of data.</p>"},{"location":"web-traffic/#pixels-and-single-page-application-spa-sites","title":"Pixels and Single-Page-Application (SPA) sites","text":"<p>SPAs can sometimes be an initial challenge for a tracking pixel based approach if the pixel is not being re-loaded when user navigates to a new page. If your pixel is placed in your site's footer, for instance, it may not be re-loaded when a user navigates to a new page.</p> <p>To ensure your pixel will be triggered on any page view within an SPA, there are two options:</p> <ol> <li>If you have a standard template for each page's dynamic content, you can insert your pixel into that template, so it is re-rendered anytime the page changes</li> <li>Use the following script (or similar) to dynamically load your pixel on page change:</li> </ol> <pre><code>    (function () {\nconst pixelID = '&lt;your pixelID&gt;';\nlet lastHref = null;\n\nfunction sendScarfPing() {\nconst currentHref = window.location.href;\nif (currentHref === lastHref) return;\nlastHref = currentHref;\n\nconst url = `https://static.scarf.sh/a.png?x-pxid=${pixelID}`;\nconst img = new Image();\nimg.referrerPolicy = 'no-referrer-when-downgrade';\nimg.src = url;\n}\n\n['pushState', 'replaceState'].forEach(fn =&gt; {\nconst original = history[fn];\nhistory[fn] = function () {\noriginal.apply(this, arguments);\nwindow.dispatchEvent(new Event('scarf:locationchange'));\n};\n});\n\nwindow.addEventListener('hashchange', sendScarfPing);\nwindow.addEventListener('popstate', sendScarfPing);\nwindow.addEventListener('scarf:locationchange', sendScarfPing);\n\nsendScarfPing(); // initial page load\n})();\n</code></pre>"},{"location":"web-traffic/#caveats","title":"Caveats","text":""},{"location":"web-traffic/#obfuscation-on-github","title":"Obfuscation on GitHub","text":"<p>Scarf pixel tracking will work on standard web pages, rendered markdown documentation on package registry sites like Docker Hub, npm, and PyPI, and anywhere an image can be embedded, but a place with notably less visibility is GitHub. When GitHub renders markdown, it rewrites any image URLs from their original web address to <code>https://camo.githubusercontent.com/$</code>, where GitHub hosts any linked images themselves. This prevents Scarf from providing insights like company information to maintainers, since the end-user information is obfuscated from Scarf.</p> <p>This prefetching also obscures the page being viewed on GitHub itself. One workaround is to add page information to your query parameter on each page you embed your pixel.</p> <pre><code>&lt;!-- explicitly send a `page` query parameter to Scarf to work around GitHub pre-caching --&gt;\n&lt;img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=abc&amp;page=README.md\" /&gt;\n</code></pre> <p>The above will send data to scarf with a specific <code>page</code> parameter.</p>"},{"location":"web-traffic/#learn-more","title":"Learn more","text":"<p>Learn how to use Scarf Pixels for documentation insights in this playbook.</p>"}]}